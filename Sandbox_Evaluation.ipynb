{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbedb086-8835-4b66-85fc-0d8dbb422f45",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97963682-a4fe-4419-8333-a73a680ced12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import pickle\n",
    "from ai_clinician.modeling.models.komorowski_model import *\n",
    "from ai_clinician.modeling.models.common import *\n",
    "from ai_clinician.modeling.columns import C_OUTCOME\n",
    "from ai_clinician.preprocessing.utils import load_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tqdm.tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "701c5041-5354-4572-86b6-d5a120a50f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded_feature_weights [0.3943926  0.27756421 0.24343556 0.23991552 0.21412183 0.18868424\n",
      " 0.1835645  0.18020105 0.17104588 0.1679103  0.16144925 0.15938839\n",
      " 0.15371076 0.1529229  0.15073967 0.1478161  0.1438637  0.1434054\n",
      " 0.1417021  0.14009531 0.11779231 0.11505856 0.11428096 0.11317841\n",
      " 0.11120712 0.11085235 0.1085031  0.10663935 0.10595175 0.10565174\n",
      " 0.10279287 0.10241132 0.10177746 0.10109605 0.09985348 0.09779006\n",
      " 0.09721884 0.09706016 0.09613519 0.09512068 1.        ]\n"
     ]
    }
   ],
   "source": [
    "def create_args():\n",
    "    parser = argparse.ArgumentParser(description=(\n",
    "        'Evaluates an AI Clinician model on the MIMIC-IV test set.'\n",
    "    ))\n",
    "    parser.add_argument('data', type=str,\n",
    "                        help='Model data directory (should contain train and test directories)')\n",
    "    parser.add_argument('model', type=str,\n",
    "                        help='Path to pickle file containing the model')\n",
    "    parser.add_argument('--out', dest='out_path', type=str, default=None,\n",
    "                        help='Path to pickle file at which to write out results (optional)')\n",
    "    parser.add_argument('--gamma', dest='gamma', type=float, default=0.99,\n",
    "                        help='Decay for reward values (default 0.99)')\n",
    "    parser.add_argument('--soften-factor', dest='soften_factor', type=float, default=0.05,\n",
    "                        help='Amount by which to soften factors (random actions will be chosen this proportion of the time)')\n",
    "    parser.add_argument('--num-iter-ql', dest='num_iter_ql', type=int, default=6,\n",
    "                        help='Number of bootstrappings to use for TD learning (physician policy)')\n",
    "    parser.add_argument('--num-iter-wis', dest='num_iter_wis', type=int, default=1000,\n",
    "                        help='Number of bootstrappings to use for WIS estimation (AI policy)')\n",
    "    \n",
    "    # Simulate command-line arguments\n",
    "    simulated_input = [\n",
    "        '/home/lkapral/RRT_mimic_iv/data/model',     # Replace with your actual data directory\n",
    "        '/home/lkapral/RRT_mimic_iv/data/model/models_penal/0.22/model_params_40/top5/top5_model_2.pkl',    # Replace with your actual model path\n",
    "        #'/home/lkapral/RRT_mimic_iv/data/model/models/model_params/best_model.pkl',\n",
    "        '--gamma', '0.99',\n",
    "        '--soften-factor', '0.01',\n",
    "        '--num-iter-ql', '6',\n",
    "        '--num-iter-wis', '500'\n",
    "    ]\n",
    "    \n",
    "    return parser.parse_args(simulated_input)\n",
    "\n",
    "# Use the args\n",
    "args = create_args()\n",
    "output_dir = '/home/lkapral/RRT_mimic_iv/data/model'\n",
    "data_dir = args.data\n",
    "model = AIClinicianModel.load(args.model)\n",
    "assert model.metadata is not None, \"Model missing metadata needed to generate actions\"\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "652eded7-5af6-4965-b77c-f994a319b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_num_features = 40\n",
    "\n",
    "feature_importance = pd.read_csv('/home/lkapral/RRT_mimic_iv/data/model/combined_feature_importances.csv')\n",
    "\n",
    "weights = feature_importance.head(fixed_num_features)['Combined_Average'].values\n",
    "feature_weights = weights / np.linalg.norm(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e49e67a-dceb-4094-8159-35070ea92480",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_features = feature_importance.head(fixed_num_features)['Feature'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abba95ff-9583-4a17-8bb0-ac9411df1470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create actions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIMICraw = load_csv(os.path.join(data_dir, \"test\", \"MIMICraw.csv\"))\n",
    "#MIMICzs = load_csv(os.path.join(data_dir, \"test\", \"MIMICzs.csv\"))\n",
    "MIMICzs = pd.read_csv(os.path.join(data_dir, \"test\", \"MIMICzs.csv\"))\n",
    "metadata = load_csv(os.path.join(data_dir, \"test\", \"metadata.csv\"))\n",
    "unique_icu_stays = metadata[C_ICUSTAYID].unique()\n",
    "\n",
    "# Create actions based on RRT\n",
    "print(\"Create actions\")\n",
    "\n",
    "# Define RRT-related columns\n",
    "rrt_cols = [\n",
    "    'Ultrafiltrate_Output',\n",
    "    'Blood_Flow',\n",
    "    'Hourly_Patient_Fluid_Removal',\n",
    "    'Dialysate_Rate',\n",
    "    'Hemodialysis_Output',  # Ensure the column name matches your DataFrame\n",
    "    'Citrate',\n",
    "    'Prefilter_Replacement_Rate',\n",
    "    'Postfilter_Replacement_Rate'\n",
    "]\n",
    "\n",
    "# Create 'action' column\n",
    "rrt_actions = (~MIMICraw[rrt_cols].isna() & (MIMICraw[rrt_cols] != 0)).any(axis=1)\n",
    "MIMICraw['action'] = rrt_actions.astype(int)\n",
    "# Actions array\n",
    "\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54654a50-a8b8-4035-91fc-bf9a37f5d5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16283"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(metadata['icustayid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65020d27-a978-4091-9efe-483289eb4413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actions': {'n_action_bins': 2,\n",
       "  'action_bins': array([0. , 0.5, 1. ]),\n",
       "  'action_medians': array([0, 1])},\n",
       " 'split': {'train_ids': array([36985741, 31150594, 31642374, ..., 37790429, 39409631, 32468504]),\n",
       "  'val_ids': array([35730908, 38113970, 31173295, ..., 39227723, 35718415, 33523977])},\n",
       " 'eval_params': {'num_iter_ql': 6, 'num_iter_wis': 700},\n",
       " 'wis_score': 80.9727863599537,\n",
       " 'rank': 3,\n",
       " 'model_num': 508}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb48c40e-4f8b-47ac-a60d-91d451c3c867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MIMICraw['RRT'] = MIMICraw['action']\n",
    "MIMICzs['RRT'] = MIMICraw['action']\n",
    "\n",
    "# MIMICraw['icustayid'] = metadata['icustayid']\n",
    "\n",
    "# MIMICraw['action'] = MIMICraw.groupby('icustayid')['action'].transform(\n",
    "#     lambda x: x.ne(x.shift().fillna(x)).astype(int)\n",
    "# )\n",
    "# MIMICraw.drop(columns=['icustayid'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "244d9af3-54ce-424a-885a-5ca6dfc8cdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_RRT = MIMICraw['action'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a03f5e91-ee9d-4687-95fc-317ab7578188",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cluster_states = model.n_cluster_states\n",
    "\n",
    "# Update the number of actions to 2 (binary actions)\n",
    "n_actions = 2\n",
    "model.n_actions = n_actions  # Update model's n_actions\n",
    "\n",
    "# Define action_medians and action_bins for binary actions\n",
    "action_medians = np.array([0, 1])\n",
    "action_bins = np.array([0, 0.5, 1])\n",
    "\n",
    "# Update model's action_bins and action_medians\n",
    "model.metadata['actions']['action_bins'] = action_bins\n",
    "model.metadata['actions']['action_medians'] = action_medians\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9023873-a203-4c92-bd81-4b1aba4f8549",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIMICzs = MIMICzs[reduced_features+ ['RRT']]\n",
    "MIMICraw = MIMICraw[reduced_features + ['RRT']]\n",
    "feature_weights = np.append(feature_weights,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69a5c97f-fc7b-4ecf-a3a0-08aa6a8cee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['output_step', 'Creatinine', 'SOFA', 'cumulated_balance',\n",
    "       'Platelets_count', 'BUN', 'Calcium', 'Chloride', 'Anion_Gap',\n",
    "       'output_total', 'input_total', 'WBC_count', 'age', 'Phosphorous',\n",
    "       'RASS', 'Temp_C', 'Total_bili', 'O2flow', 'Sodium', 'max_dose_vaso',\n",
    "       'Weight_kg', 'GCS', 'PTT', 'RBC_count', 'RR', 'PT', 'PAWmean',\n",
    "       'Ionised_Ca', 'SpO2', 'Ht', 'Hb', 'SGOT', 'extubated', 'LDH', 'FiO2_1',\n",
    "       'HCO3', 'SGPT', 'Potassium', 'MinuteVentil', 'Shock_Index',\n",
    "       'Arterial_pH', 'MeanBP', 'Glucose', 'INR', 'HR', 'input_step',\n",
    "       'TidalVolume', 'PaO2_FiO2', 'Albumin', 'SysBP', 'paO2', 'PAWpeak',\n",
    "       'PAWplateau', 'DiaBP', 'Fibrinogen', 'Arterial_BE', 'paCO2',\n",
    "       'Magnesium', 'Arterial_lactate', 'CVP', 'PEEP', 'Height_cm', 'CK_MB',\n",
    "       'mechvent', 'ETCO2', 'Troponin', 'Absolute_Neutrophil_Count', 'SaO2',\n",
    "       'SIRS', 'Triglyceride', 'RRT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4a9048-8902-4a70-b370-8dec37361412",
   "metadata": {},
   "source": [
    "# Policy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "796f9155-8cbf-4344-b13e-c91891f4f60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, RocCurveDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fab9e54-2ceb-4553-a088-2190b5081fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on MIMIC test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TD evaluation: 100%|██████████████████████████████████████████████████████████████████████| 6/6 [00:11<00:00,  1.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeroing out 445/1004 transitions\n",
      "Create reward matrix R(S, A)\n"
     ]
    }
   ],
   "source": [
    "blocs = metadata[C_BLOC].values\n",
    "stay_ids = metadata[C_ICUSTAYID].values\n",
    "outcomes = metadata[C_OUTCOME].values  # 1 if patient died, 0 if survived\n",
    "\n",
    "print(\"Evaluating on MIMIC test set...\")\n",
    "states = model.compute_states(MIMICzs.values)\n",
    "\n",
    "records = build_complete_record_sequences(\n",
    "    metadata,\n",
    "    states,\n",
    "    actions_RRT,\n",
    "    model.absorbing_states,\n",
    "    model.rewards\n",
    ")\n",
    "\n",
    "# Evaluate the physician's policy using Temporal Difference (TD) Learning\n",
    "test_bootql = evaluate_physician_policy_td(\n",
    "    records,\n",
    "    model.physician_policy,\n",
    "    args.gamma,\n",
    "    args.num_iter_ql,\n",
    "    model.n_cluster_states\n",
    ")\n",
    "physpol_test, transitionr_test, R_test = compute_physician_policy(\n",
    "    records,\n",
    "    model.n_states,\n",
    "    model.n_actions,\n",
    "    model.absorbing_states,\n",
    "    reward_val=model.reward_val,\n",
    "    transition_threshold=model.transition_threshold,\n",
    ")\n",
    "# Compute probabilities for policy evaluation\n",
    "phys_probs = model.compute_physician_probabilities(states=states, actions=actions_RRT)\n",
    "model_probs = model.compute_probabilities(states=states, actions=actions_RRT)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34690bb4-d61b-41b6-ade1-2664a6e6a016",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WIS estimation: 100%|█████████████████████████████████████████████████████████████████| 500/500 [00:42<00:00, 11.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results:\n",
      "\n",
      "1. Physician's Policy Evaluation (Temporal Difference Learning):\n",
      "- Mean Value of Physician's Policy: 61.4033\n",
      "- 95% Upper Bound of Physician's Policy Value: 65.6189\n",
      "- 99% Upper Bound of Physician's Policy Value: 65.8934\n",
      "\n",
      "2. AI Policy Evaluation (Weighted Importance Sampling):\n",
      "- Mean Value of AI Policy: 93.0945\n",
      "- 5% Lower Bound of AI Policy Value: 86.2104\n",
      "- 1% Lower Bound of AI Policy Value: 69.5870\n",
      "- 95% Upper Bound of AI Policy Value: 94.1477\n",
      "\n",
      "Interpretation:\n",
      "The policy values represent the expected future rewards (e.g., survival) associated with each policy.\n",
      "A higher policy value suggests better expected patient outcomes.\n",
      "The AI policy's mean value and lower bounds indicate it may outperform the physician's policy.\n",
      "However, confidence intervals overlap, and clinical significance should be carefully evaluated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the AI policy using Weighted Importance Sampling (WIS)\n",
    "test_bootwis, _,  estimates = evaluate_policy_wis(\n",
    "    metadata,\n",
    "    phys_probs,\n",
    "    model_probs,\n",
    "    model.rewards,\n",
    "    args.gamma,\n",
    "    args.num_iter_wis,\n",
    "    save_roh=True\n",
    ")\n",
    "\n",
    "# Prepare model statistics\n",
    "model_stats = {}\n",
    "model_stats['test_bootql_0.95'] = np.quantile(test_bootql, 0.95)   # Physicians' 95% Upper Bound\n",
    "model_stats['test_bootql_mean'] = np.nanmean(test_bootql)\n",
    "model_stats['test_bootql_0.99'] = np.quantile(test_bootql, 0.99)\n",
    "model_stats['test_bootwis_mean'] = np.nanmean(test_bootwis)    \n",
    "model_stats['test_bootwis_0.01'] = np.quantile(test_bootwis, 0.01)  \n",
    "wis_95lb = np.quantile(test_bootwis, 0.05)  # AI's 95% Lower Bound\n",
    "model_stats['test_bootwis_0.05'] = wis_95lb\n",
    "model_stats['test_bootwis_0.95'] = np.quantile(test_bootwis, 0.95)\n",
    "\n",
    "# Display the results with explanations\n",
    "print(\"\\nEvaluation Results:\")\n",
    "\n",
    "print(\"\\n1. Physician's Policy Evaluation (Temporal Difference Learning):\")\n",
    "print(f\"- Mean Value of Physician's Policy: {model_stats['test_bootql_mean']:.4f}\")\n",
    "print(f\"- 95% Upper Bound of Physician's Policy Value: {model_stats['test_bootql_0.95']:.4f}\")\n",
    "print(f\"- 99% Upper Bound of Physician's Policy Value: {model_stats['test_bootql_0.99']:.4f}\")\n",
    "\n",
    "print(\"\\n2. AI Policy Evaluation (Weighted Importance Sampling):\")\n",
    "print(f\"- Mean Value of AI Policy: {model_stats['test_bootwis_mean']:.4f}\")\n",
    "print(f\"- 5% Lower Bound of AI Policy Value: {model_stats['test_bootwis_0.05']:.4f}\")\n",
    "print(f\"- 1% Lower Bound of AI Policy Value: {model_stats['test_bootwis_0.01']:.4f}\")\n",
    "print(f\"- 95% Upper Bound of AI Policy Value: {model_stats['test_bootwis_0.95']:.4f}\")\n",
    "\n",
    "# Interpret the results in clinical terms\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"The policy values represent the expected future rewards (e.g., survival) associated with each policy.\")\n",
    "print(\"A higher policy value suggests better expected patient outcomes.\")\n",
    "print(\"The AI policy's mean value and lower bounds indicate it may outperform the physician's policy.\")\n",
    "print(\"However, confidence intervals overlap, and clinical significance should be carefully evaluated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c42b61a-7e67-4d43-a247-e41b0cb0f7dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "414c3125-0eb3-4879-adee-d5febcf6097d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Plot histogram with y-axis on a logarithmic scale\n",
    "plt.hist(estimates, bins=1000, log=True, edgecolor='black')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency (log scale)')\n",
    "plt.title('Estimates')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d3d8976-d685-4a57-a77e-a55bc68c5bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.load('rhos.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c764b4b6-b594-47d3-83e1-c1dc0c196853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126496.50615991898"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhos.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27db9298-6362-47ed-b872-f071eb2b57a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Create logarithmically spaced bins for the x-axis\n",
    "bins = np.logspace(np.log10(rhos.min()), np.log10(rhos.max()), 10000)\n",
    "\n",
    "# Plot the histogram:\n",
    "# - bins: use logarithmically spaced bins\n",
    "# - log=True: y-axis is logarithmic\n",
    "plt.hist(rhos, bins=bins, edgecolor='black', log=True)\n",
    "\n",
    "# Set x-axis to logarithmic scale\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.xlabel('Value (log scale)')\n",
    "plt.ylabel('Frequency (log scale)')\n",
    "plt.title('Policy Ratio')\n",
    "\n",
    "# Save the plot if desired\n",
    "plt.savefig('log_log_histogram.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d2e372-f174-48a7-a223-f3df5881be13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0487e65-d7c6-4b0a-b010-da16e920e42d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5686fc8b-5a43-4156-bc8f-1812150c5154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dice_rl_TU_Vienna.value import get_get_policy_value_dataframe\n",
    "from dice_rl_TU_Vienna.runners.tabular_dice_runner import TabularDiceRunner_Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a771de12-6699-4afb-8705-d0ab8c21037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_DICE_Df(records, model_probs, phys_probs, path=None):\n",
    "    \"\"\"\n",
    "    Creates a DataFrame for DICE analysis by adding probability columns\n",
    "    and saves it as a parquet file.\n",
    "\n",
    "    In this version, model_probs and phys_probs represent the probability \n",
    "    for the observed action in dice_df['action']. Specifically:\n",
    "      - If action == 0, then the provided probability is for action 0,\n",
    "        and the probability for action 1 is 1 - probability.\n",
    "      - If action == 1, then the provided probability is for action 1,\n",
    "        and the probability for action 0 is 1 - probability.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    records : pd.DataFrame\n",
    "        The input DataFrame containing the records.\n",
    "    model_probs : array-like\n",
    "        Probabilities corresponding to the action in the model's policy.\n",
    "    phys_probs : array-like\n",
    "        Probabilities corresponding to the action in the physician's policy.\n",
    "    path : str, optional\n",
    "        Directory path where the parquet file will be saved.\n",
    "        Defaults to the current directory.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        The modified DataFrame with added probability columns.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import os\n",
    "\n",
    "    # Make a copy to avoid modifying the original DataFrame\n",
    "    dice_df = records.copy()\n",
    "\n",
    "    # Align probabilities with the DataFrame's index\n",
    "    model_probs = pd.Series(model_probs, index=dice_df.index)\n",
    "    phys_probs = pd.Series(phys_probs, index=dice_df.index)\n",
    "\n",
    "    dice_df[\"action\"] = dice_df[\"action\"].replace(-1, np.nan)\n",
    "    \n",
    "    # Fill NaN values with the previous valid action\n",
    "    dice_df[\"action\"] = dice_df[\"action\"].fillna(method=\"ffill\")\n",
    "\n",
    "    dice_df[\"action\"] = dice_df[\"action\"].astype(int)\n",
    "\n",
    "    # For the model's probabilities: if action==0, p0 is the provided prob;\n",
    "    # if action==1, then p1 is the provided prob.\n",
    "    dice_df['p0_model'] = np.where(dice_df['action'] == 0, model_probs, 1.0 - model_probs)\n",
    "    dice_df['p1_model'] = np.where(dice_df['action'] == 1, model_probs, 1.0 - model_probs)\n",
    "    dice_df['probabilities_model'] = dice_df[['p0_model', 'p1_model']].values.tolist()\n",
    "\n",
    "    # For the physician's probabilities: similarly, interpret the provided prob\n",
    "    dice_df['p0_phys'] = np.where(dice_df['action'] == 0, phys_probs, 1.0 - phys_probs)\n",
    "    dice_df['p1_phys'] = np.where(dice_df['action'] == 1, phys_probs, 1.0 - phys_probs)\n",
    "    dice_df['probabilities_phys'] = dice_df[['p0_phys', 'p1_phys']].values.tolist()\n",
    "\n",
    "    # Handle the file path: default to current working directory if none provided\n",
    "    if path is None:\n",
    "        path = os.getcwd()\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # Full path to save the parquet file\n",
    "    file_path = os.path.join(path, 'DICE_df_mimic.parquet')\n",
    "\n",
    "    # Save the DataFrame to a parquet file\n",
    "    dice_df.to_parquet(file_path)\n",
    "\n",
    "    return dice_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8488fdc-014e-4c1e-a1aa-92dea18c044f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2829916/2656048954.py:44: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  dice_df[\"action\"] = dice_df[\"action\"].fillna(method=\"ffill\")\n"
     ]
    }
   ],
   "source": [
    "dice_df= make_DICE_Df(records, model_probs, phys_probs, path=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb5f740e-d4bb-4c97-99b3-8e21fe5cb5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bloc</th>\n",
       "      <th>icustayid</th>\n",
       "      <th>state</th>\n",
       "      <th>action</th>\n",
       "      <th>outcome</th>\n",
       "      <th>reward</th>\n",
       "      <th>p0_model</th>\n",
       "      <th>p1_model</th>\n",
       "      <th>probabilities_model</th>\n",
       "      <th>p0_phys</th>\n",
       "      <th>p1_phys</th>\n",
       "      <th>probabilities_phys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>18</td>\n",
       "      <td>30014019</td>\n",
       "      <td>464</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>19</td>\n",
       "      <td>30014019</td>\n",
       "      <td>464</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>20</td>\n",
       "      <td>30014019</td>\n",
       "      <td>464</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>21</td>\n",
       "      <td>30014019</td>\n",
       "      <td>464</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>22</td>\n",
       "      <td>30014019</td>\n",
       "      <td>464</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>23</td>\n",
       "      <td>30014019</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1</td>\n",
       "      <td>30015055</td>\n",
       "      <td>370</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2</td>\n",
       "      <td>30015055</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>3</td>\n",
       "      <td>30015055</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.980110</td>\n",
       "      <td>0.019890</td>\n",
       "      <td>[0.9801098901098901, 0.019890109890109864]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>4</td>\n",
       "      <td>30015055</td>\n",
       "      <td>433</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>5</td>\n",
       "      <td>30015055</td>\n",
       "      <td>501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>1</td>\n",
       "      <td>30015933</td>\n",
       "      <td>430</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2</td>\n",
       "      <td>30015933</td>\n",
       "      <td>290</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>3</td>\n",
       "      <td>30015933</td>\n",
       "      <td>414</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>4</td>\n",
       "      <td>30015933</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.980110</td>\n",
       "      <td>0.019890</td>\n",
       "      <td>[0.9801098901098901, 0.019890109890109864]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>5</td>\n",
       "      <td>30015933</td>\n",
       "      <td>414</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>6</td>\n",
       "      <td>30015933</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>9</td>\n",
       "      <td>30015933</td>\n",
       "      <td>240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.871726</td>\n",
       "      <td>0.128274</td>\n",
       "      <td>[0.8717256637168141, 0.12827433628318585]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>10</td>\n",
       "      <td>30015933</td>\n",
       "      <td>501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1</td>\n",
       "      <td>30016345</td>\n",
       "      <td>393</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2</td>\n",
       "      <td>30016345</td>\n",
       "      <td>501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1</td>\n",
       "      <td>30017005</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2</td>\n",
       "      <td>30017005</td>\n",
       "      <td>487</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.940116</td>\n",
       "      <td>0.059884</td>\n",
       "      <td>[0.9401162790697675, 0.05988372093023253]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3</td>\n",
       "      <td>30017005</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>[0.010000000000000009, 0.99]</td>\n",
       "      <td>0.313600</td>\n",
       "      <td>0.686400</td>\n",
       "      <td>[0.3136, 0.6864]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>4</td>\n",
       "      <td>30017005</td>\n",
       "      <td>335</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>[0.010000000000000009, 0.99]</td>\n",
       "      <td>0.252365</td>\n",
       "      <td>0.747635</td>\n",
       "      <td>[0.25236514522821585, 0.7476348547717842]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>5</td>\n",
       "      <td>30017005</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.01]</td>\n",
       "      <td>0.257500</td>\n",
       "      <td>0.742500</td>\n",
       "      <td>[0.25750000000000006, 0.7424999999999999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>6</td>\n",
       "      <td>30017005</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.01]</td>\n",
       "      <td>0.257500</td>\n",
       "      <td>0.742500</td>\n",
       "      <td>[0.25750000000000006, 0.7424999999999999]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>7</td>\n",
       "      <td>30017005</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>[0.01, 0.99]</td>\n",
       "      <td>0.742500</td>\n",
       "      <td>0.257500</td>\n",
       "      <td>[0.7424999999999999, 0.25750000000000006]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>8</td>\n",
       "      <td>30017005</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>9</td>\n",
       "      <td>30017005</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.971066</td>\n",
       "      <td>0.028934</td>\n",
       "      <td>[0.9710655737704917, 0.02893442622950826]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>10</td>\n",
       "      <td>30017005</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.860957</td>\n",
       "      <td>0.139043</td>\n",
       "      <td>[0.8609572301425662, 0.1390427698574338]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>11</td>\n",
       "      <td>30017005</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.860957</td>\n",
       "      <td>0.139043</td>\n",
       "      <td>[0.8609572301425662, 0.1390427698574338]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>12</td>\n",
       "      <td>30017005</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.756210</td>\n",
       "      <td>0.243790</td>\n",
       "      <td>[0.7562099125364432, 0.2437900874635568]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>13</td>\n",
       "      <td>30017005</td>\n",
       "      <td>259</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>14</td>\n",
       "      <td>30017005</td>\n",
       "      <td>279</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>[0.91, 0.08999999999999997]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>15</td>\n",
       "      <td>30017005</td>\n",
       "      <td>279</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>[0.91, 0.08999999999999997]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>16</td>\n",
       "      <td>30017005</td>\n",
       "      <td>279</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>[0.91, 0.08999999999999997]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>17</td>\n",
       "      <td>30017005</td>\n",
       "      <td>279</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>[0.91, 0.08999999999999997]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>18</td>\n",
       "      <td>30017005</td>\n",
       "      <td>279</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>[0.91, 0.08999999999999997]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>19</td>\n",
       "      <td>30017005</td>\n",
       "      <td>279</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>[0.91, 0.08999999999999997]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>20</td>\n",
       "      <td>30017005</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>21</td>\n",
       "      <td>30017005</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>22</td>\n",
       "      <td>30017005</td>\n",
       "      <td>501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1</td>\n",
       "      <td>30017538</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>2</td>\n",
       "      <td>30017538</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>3</td>\n",
       "      <td>30017538</td>\n",
       "      <td>501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1</td>\n",
       "      <td>30018043</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2</td>\n",
       "      <td>30018043</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>3</td>\n",
       "      <td>30018043</td>\n",
       "      <td>501</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1</td>\n",
       "      <td>30020923</td>\n",
       "      <td>362</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bloc  icustayid  state  action  outcome  reward  p0_model  p1_model  \\\n",
       "150    18   30014019    464       0        1       0      0.99      0.01   \n",
       "151    19   30014019    464       0        1       0      0.99      0.01   \n",
       "152    20   30014019    464       0        1       0      0.99      0.01   \n",
       "153    21   30014019    464       0        1       0      0.99      0.01   \n",
       "154    22   30014019    464       0        1       0      0.99      0.01   \n",
       "155    23   30014019    500       0        1    -100      0.99      0.01   \n",
       "156     1   30015055    370       0        0       0      0.99      0.01   \n",
       "157     2   30015055     94       0        0       0      0.99      0.01   \n",
       "158     3   30015055     59       0        0       0      0.99      0.01   \n",
       "159     4   30015055    433       0        0       0      0.99      0.01   \n",
       "160     5   30015055    501       0        0     100      0.99      0.01   \n",
       "161     1   30015933    430       0        0       0      0.99      0.01   \n",
       "162     2   30015933    290       0        0       0      0.99      0.01   \n",
       "163     3   30015933    414       0        0       0      0.99      0.01   \n",
       "164     4   30015933     59       0        0       0      0.99      0.01   \n",
       "165     5   30015933    414       0        0       0      0.99      0.01   \n",
       "166     6   30015933     90       0        0       0      0.99      0.01   \n",
       "167     9   30015933    240       0        0       0      0.99      0.01   \n",
       "168    10   30015933    501       0        0     100      0.99      0.01   \n",
       "169     1   30016345    393       0        0       0      0.99      0.01   \n",
       "170     2   30016345    501       0        0     100      0.99      0.01   \n",
       "171     1   30017005     20       0        0       0      0.99      0.01   \n",
       "172     2   30017005    487       0        0       0      0.99      0.01   \n",
       "173     3   30017005     39       1        0       0      0.01      0.99   \n",
       "174     4   30017005    335       1        0       0      0.01      0.99   \n",
       "175     5   30017005     65       1        0       0      0.99      0.01   \n",
       "176     6   30017005     65       1        0       0      0.99      0.01   \n",
       "177     7   30017005     65       0        0       0      0.01      0.99   \n",
       "178     8   30017005     20       0        0       0      0.99      0.01   \n",
       "179     9   30017005     31       0        0       0      0.99      0.01   \n",
       "180    10   30017005    124       0        0       0      0.99      0.01   \n",
       "181    11   30017005    124       0        0       0      0.99      0.01   \n",
       "182    12   30017005    284       0        0       0      0.99      0.01   \n",
       "183    13   30017005    259       0        0       0      0.99      0.01   \n",
       "184    14   30017005    279       0        0       0      0.99      0.01   \n",
       "185    15   30017005    279       0        0       0      0.99      0.01   \n",
       "186    16   30017005    279       0        0       0      0.99      0.01   \n",
       "187    17   30017005    279       0        0       0      0.99      0.01   \n",
       "188    18   30017005    279       0        0       0      0.99      0.01   \n",
       "189    19   30017005    279       0        0       0      0.99      0.01   \n",
       "190    20   30017005    212       0        0       0      0.99      0.01   \n",
       "191    21   30017005    212       0        0       0      0.99      0.01   \n",
       "192    22   30017005    501       0        0     100      0.99      0.01   \n",
       "193     1   30017538    113       0        0       0      0.99      0.01   \n",
       "194     2   30017538    113       0        0       0      0.99      0.01   \n",
       "195     3   30017538    501       0        0     100      0.99      0.01   \n",
       "196     1   30018043     27       0        0       0      0.99      0.01   \n",
       "197     2   30018043     64       0        0       0      0.99      0.01   \n",
       "198     3   30018043    501       0        0     100      0.99      0.01   \n",
       "199     1   30020923    362       0        1       0      0.99      0.01   \n",
       "\n",
       "              probabilities_model   p0_phys   p1_phys  \\\n",
       "150  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "151  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "152  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "153  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "154  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "155  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "156  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "157  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "158  [0.99, 0.010000000000000009]  0.980110  0.019890   \n",
       "159  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "160  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "161  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "162  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "163  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "164  [0.99, 0.010000000000000009]  0.980110  0.019890   \n",
       "165  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "166  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "167  [0.99, 0.010000000000000009]  0.871726  0.128274   \n",
       "168  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "169  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "170  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "171  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "172  [0.99, 0.010000000000000009]  0.940116  0.059884   \n",
       "173  [0.010000000000000009, 0.99]  0.313600  0.686400   \n",
       "174  [0.010000000000000009, 0.99]  0.252365  0.747635   \n",
       "175                  [0.99, 0.01]  0.257500  0.742500   \n",
       "176                  [0.99, 0.01]  0.257500  0.742500   \n",
       "177                  [0.01, 0.99]  0.742500  0.257500   \n",
       "178  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "179  [0.99, 0.010000000000000009]  0.971066  0.028934   \n",
       "180  [0.99, 0.010000000000000009]  0.860957  0.139043   \n",
       "181  [0.99, 0.010000000000000009]  0.860957  0.139043   \n",
       "182  [0.99, 0.010000000000000009]  0.756210  0.243790   \n",
       "183  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "184  [0.99, 0.010000000000000009]  0.910000  0.090000   \n",
       "185  [0.99, 0.010000000000000009]  0.910000  0.090000   \n",
       "186  [0.99, 0.010000000000000009]  0.910000  0.090000   \n",
       "187  [0.99, 0.010000000000000009]  0.910000  0.090000   \n",
       "188  [0.99, 0.010000000000000009]  0.910000  0.090000   \n",
       "189  [0.99, 0.010000000000000009]  0.910000  0.090000   \n",
       "190  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "191  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "192  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "193  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "194  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "195  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "196  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "197  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "198  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "199  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "\n",
       "                             probabilities_phys  \n",
       "150                [0.99, 0.010000000000000009]  \n",
       "151                [0.99, 0.010000000000000009]  \n",
       "152                [0.99, 0.010000000000000009]  \n",
       "153                [0.99, 0.010000000000000009]  \n",
       "154                [0.99, 0.010000000000000009]  \n",
       "155                [0.99, 0.010000000000000009]  \n",
       "156                [0.99, 0.010000000000000009]  \n",
       "157                [0.99, 0.010000000000000009]  \n",
       "158  [0.9801098901098901, 0.019890109890109864]  \n",
       "159                [0.99, 0.010000000000000009]  \n",
       "160                [0.99, 0.010000000000000009]  \n",
       "161                [0.99, 0.010000000000000009]  \n",
       "162                [0.99, 0.010000000000000009]  \n",
       "163                [0.99, 0.010000000000000009]  \n",
       "164  [0.9801098901098901, 0.019890109890109864]  \n",
       "165                [0.99, 0.010000000000000009]  \n",
       "166                [0.99, 0.010000000000000009]  \n",
       "167   [0.8717256637168141, 0.12827433628318585]  \n",
       "168                [0.99, 0.010000000000000009]  \n",
       "169                [0.99, 0.010000000000000009]  \n",
       "170                [0.99, 0.010000000000000009]  \n",
       "171                [0.99, 0.010000000000000009]  \n",
       "172   [0.9401162790697675, 0.05988372093023253]  \n",
       "173                            [0.3136, 0.6864]  \n",
       "174   [0.25236514522821585, 0.7476348547717842]  \n",
       "175   [0.25750000000000006, 0.7424999999999999]  \n",
       "176   [0.25750000000000006, 0.7424999999999999]  \n",
       "177   [0.7424999999999999, 0.25750000000000006]  \n",
       "178                [0.99, 0.010000000000000009]  \n",
       "179   [0.9710655737704917, 0.02893442622950826]  \n",
       "180    [0.8609572301425662, 0.1390427698574338]  \n",
       "181    [0.8609572301425662, 0.1390427698574338]  \n",
       "182    [0.7562099125364432, 0.2437900874635568]  \n",
       "183                [0.99, 0.010000000000000009]  \n",
       "184                 [0.91, 0.08999999999999997]  \n",
       "185                 [0.91, 0.08999999999999997]  \n",
       "186                 [0.91, 0.08999999999999997]  \n",
       "187                 [0.91, 0.08999999999999997]  \n",
       "188                 [0.91, 0.08999999999999997]  \n",
       "189                 [0.91, 0.08999999999999997]  \n",
       "190                [0.99, 0.010000000000000009]  \n",
       "191                [0.99, 0.010000000000000009]  \n",
       "192                [0.99, 0.010000000000000009]  \n",
       "193                [0.99, 0.010000000000000009]  \n",
       "194                [0.99, 0.010000000000000009]  \n",
       "195                [0.99, 0.010000000000000009]  \n",
       "196                [0.99, 0.010000000000000009]  \n",
       "197                [0.99, 0.010000000000000009]  \n",
       "198                [0.99, 0.010000000000000009]  \n",
       "199                [0.99, 0.010000000000000009]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_df.iloc[150:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93667290-a099-45b9-a733-fbe078aec496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8585b1b0-b3d2-46d2-bd98-c2e2deeda39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bloc</th>\n",
       "      <th>icustayid</th>\n",
       "      <th>state</th>\n",
       "      <th>action</th>\n",
       "      <th>outcome</th>\n",
       "      <th>reward</th>\n",
       "      <th>p0_model</th>\n",
       "      <th>p1_model</th>\n",
       "      <th>probabilities_model</th>\n",
       "      <th>p0_phys</th>\n",
       "      <th>p1_phys</th>\n",
       "      <th>probabilities_phys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>30002012</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.963243</td>\n",
       "      <td>0.036757</td>\n",
       "      <td>[0.9632432432432433, 0.036756756756756714]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>23</td>\n",
       "      <td>30006983</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>3</td>\n",
       "      <td>30007228</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>4</td>\n",
       "      <td>30011624</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>11</td>\n",
       "      <td>30013468</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124050</th>\n",
       "      <td>3</td>\n",
       "      <td>39964062</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.871726</td>\n",
       "      <td>0.128274</td>\n",
       "      <td>[0.8717256637168141, 0.12827433628318585]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124083</th>\n",
       "      <td>4</td>\n",
       "      <td>39965256</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.845021</td>\n",
       "      <td>0.154979</td>\n",
       "      <td>[0.8450209205020921, 0.1549790794979079]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124204</th>\n",
       "      <td>5</td>\n",
       "      <td>39977970</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124310</th>\n",
       "      <td>10</td>\n",
       "      <td>39984456</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124315</th>\n",
       "      <td>15</td>\n",
       "      <td>39984768</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2632 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        bloc  icustayid  state  action  outcome  reward  p0_model  p1_model  \\\n",
       "16         2   30002012    500       0        1    -100      0.99      0.01   \n",
       "92        23   30006983    500       0        1    -100      0.99      0.01   \n",
       "98         3   30007228    500       0        1    -100      0.99      0.01   \n",
       "109        4   30011624    500       0        1    -100      0.99      0.01   \n",
       "132       11   30013468    500       0        1    -100      0.99      0.01   \n",
       "...      ...        ...    ...     ...      ...     ...       ...       ...   \n",
       "124050     3   39964062    500       0        1    -100      0.99      0.01   \n",
       "124083     4   39965256    500       0        1    -100      0.99      0.01   \n",
       "124204     5   39977970    500       0        1    -100      0.99      0.01   \n",
       "124310    10   39984456    500       0        1    -100      0.99      0.01   \n",
       "124315    15   39984768    500       0        1    -100      0.99      0.01   \n",
       "\n",
       "                 probabilities_model   p0_phys   p1_phys  \\\n",
       "16      [0.99, 0.010000000000000009]  0.963243  0.036757   \n",
       "92      [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "98      [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "109     [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "132     [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "...                              ...       ...       ...   \n",
       "124050  [0.99, 0.010000000000000009]  0.871726  0.128274   \n",
       "124083  [0.99, 0.010000000000000009]  0.845021  0.154979   \n",
       "124204  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "124310  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "124315  [0.99, 0.010000000000000009]  0.990000  0.010000   \n",
       "\n",
       "                                probabilities_phys  \n",
       "16      [0.9632432432432433, 0.036756756756756714]  \n",
       "92                    [0.99, 0.010000000000000009]  \n",
       "98                    [0.99, 0.010000000000000009]  \n",
       "109                   [0.99, 0.010000000000000009]  \n",
       "132                   [0.99, 0.010000000000000009]  \n",
       "...                                            ...  \n",
       "124050   [0.8717256637168141, 0.12827433628318585]  \n",
       "124083    [0.8450209205020921, 0.1549790794979079]  \n",
       "124204                [0.99, 0.010000000000000009]  \n",
       "124310                [0.99, 0.010000000000000009]  \n",
       "124315                [0.99, 0.010000000000000009]  \n",
       "\n",
       "[2632 rows x 12 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_df[dice_df['state']==500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58089368-abf4-4aaa-b675-ee06d357ad42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bloc</th>\n",
       "      <th>icustayid</th>\n",
       "      <th>state</th>\n",
       "      <th>action</th>\n",
       "      <th>outcome</th>\n",
       "      <th>reward</th>\n",
       "      <th>p0_model</th>\n",
       "      <th>p1_model</th>\n",
       "      <th>probabilities_model</th>\n",
       "      <th>p0_phys</th>\n",
       "      <th>p1_phys</th>\n",
       "      <th>probabilities_phys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>30002012</td>\n",
       "      <td>352</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.963243</td>\n",
       "      <td>0.036757</td>\n",
       "      <td>[0.9632432432432433, 0.036756756756756714]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>30002012</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-100</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.01</td>\n",
       "      <td>[0.99, 0.010000000000000009]</td>\n",
       "      <td>0.963243</td>\n",
       "      <td>0.036757</td>\n",
       "      <td>[0.9632432432432433, 0.036756756756756714]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    bloc  icustayid  state  action  outcome  reward  p0_model  p1_model  \\\n",
       "15     1   30002012    352       0        1       0      0.99      0.01   \n",
       "16     2   30002012    500       0        1    -100      0.99      0.01   \n",
       "\n",
       "             probabilities_model   p0_phys   p1_phys  \\\n",
       "15  [0.99, 0.010000000000000009]  0.963243  0.036757   \n",
       "16  [0.99, 0.010000000000000009]  0.963243  0.036757   \n",
       "\n",
       "                            probabilities_phys  \n",
       "15  [0.9632432432432433, 0.036756756756756714]  \n",
       "16  [0.9632432432432433, 0.036756756756756714]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_df[dice_df['icustayid']==30002012]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629850ff-5022-4194-91ec-948cbd6aabc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_old = pd.read_parquet('/home/lkapral/RRT_mimic_iv/data/model/DICE_df_MIMIC.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b442330b-0f18-4731-a80a-bead96b6dd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_general(df, kind):\n",
    "    id = df[\"icustayid\"]\n",
    "    obs = df[\"state\"]\n",
    "    act = df[\"action\"]\n",
    "    rew = df[\"reward\"]\n",
    "    if kind == \"b\": k = \"probabilities_phys\"\n",
    "    if kind == \"e\": k = \"probabilities_model\"\n",
    "    probs = df[k]\n",
    "\n",
    "    return id, obs, act, rew, probs\n",
    "\n",
    "get_split_b = lambda df: get_split_general(df, \"b\")\n",
    "get_split_e = lambda df: get_split_general(df, \"e\")\n",
    "\n",
    "def get_episode(df, id):\n",
    "    f = df[\"icustayid\"] == id\n",
    "    return df[f]\n",
    "\n",
    "bounds = 0, model.n_cluster_states+1, 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845a7d97-4af3-40e0-8dac-f0b832bbbe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare DICE\n",
    "\n",
    "# ---------------------------------------------------------------- #\n",
    "\n",
    "sub_dir = \"behavior_MIMIC\"\n",
    "get_split = get_split_b\n",
    "\n",
    "runner_b = TabularDiceRunner_Dataframe(\n",
    "    dice_df, bounds, get_split, get_episode, data_dir, sub_dir )\n",
    "\n",
    "runner_b.set_dataset(n_pads=1)\n",
    "runner_b.set_aux_estimates()\n",
    "runner_b.set_estimator(\"TabularDice\")\n",
    "\n",
    "def get_policy_value_DICE_b_s(gamma):\n",
    "    pv_DICE, *_ = runner_b.predict(gamma, projected=True, weighted=False, modified=True, lam=1e-6)\n",
    "    return pv_DICE\n",
    "\n",
    "def get_policy_value_DICE_b_w(gamma):\n",
    "    pv_DICE, *_ = runner_b.predict(gamma, projected=True, weighted=True, modified=True, lam=1e-6)\n",
    "    return pv_DICE\n",
    "\n",
    "# ---------------------------------------------------------------- #\n",
    "\n",
    "sub_dir = \"evaluation_MIMIC\"\n",
    "get_split = get_split_e\n",
    "\n",
    "runner_e = TabularDiceRunner_Dataframe(\n",
    "    dice_df, bounds, get_split, get_episode, data_dir, sub_dir )\n",
    "\n",
    "runner_e.set_dataset(n_pads=1)\n",
    "runner_e.set_aux_estimates()\n",
    "runner_e.set_estimator(\"TabularDice\")\n",
    "\n",
    "def get_policy_value_DICE_e_s(gamma):\n",
    "    pv_DICE, *_ = runner_e.predict(gamma, projected=True, weighted=False, modified=True, lam=1e-6)\n",
    "    return pv_DICE\n",
    "\n",
    "def get_policy_value_DICE_e_w(gamma):\n",
    "    pv_DICE, *_ = runner_e.predict(gamma, projected=True, weighted=True, modified=True, lam=1e-6)\n",
    "    return pv_DICE\n",
    "\n",
    "# ---------------------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8ef38a-dfcd-4804-9065-a3a6462ba569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare OnPE\n",
    "\n",
    "get_policy_value_OnPE_b, _ = get_get_policy_value_dataframe(dice_df, get_split, get_episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b1b6b1-83b2-4af6-aa7e-5a3217bbba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.999\n",
    "\n",
    "pv_1 = get_policy_value_DICE_b_s(gamma)\n",
    "pv_2 = get_policy_value_DICE_b_w(gamma)\n",
    "pv_3 = get_policy_value_OnPE_b(gamma)\n",
    "\n",
    "print( float(pv_1), float(pv_2), float(pv_3) )\n",
    "\n",
    "pv_1 = get_policy_value_DICE_e_s(gamma)\n",
    "pv_2 = get_policy_value_DICE_e_w(gamma)\n",
    "\n",
    "print( float(pv_1), float(pv_2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0138a9-d422-43f9-98f5-0dee37ae4502",
   "metadata": {},
   "source": [
    "# Transistion probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f07773c-ce4c-4a34-ac4c-c0b74dc2b7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = model.n_actions\n",
    "S = model.n_states\n",
    "transition_matrix_train = model.transitionr\n",
    "transition_matrix_test = transitionr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4da7a6b-0295-4281-a67b-2764d0c390c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "# Assuming model.transitionr and transitionr_test are NumPy arrays\n",
    "A = model.n_actions\n",
    "S = model.n_states\n",
    "transition_matrix_train = model.transitionr        # Shape: (752, 752, 2)\n",
    "transition_matrix_test = transitionr_test          # Shape: (752, 752, 2)\n",
    "\n",
    "# Validate shapes\n",
    "assert transition_matrix_train.shape == transition_matrix_test.shape, \"Train and Test matrices must have the same shape.\"\n",
    "\n",
    "print(f\"Number of States (S): {S}\")\n",
    "print(f\"Number of Actions (A): {A}\")\n",
    "print(f\"Transition Matrix Train Shape: {transition_matrix_train.shape}\")\n",
    "print(f\"Transition Matrix Test Shape: {transition_matrix_test.shape}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345d91ae-5d5e-4ffb-8033-a6851059db36",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert transition_matrix_train.shape == transition_matrix_test.shape, \"Train and Test matrices must have the same shape.\"\n",
    "\n",
    "print(f\"Number of States (S): {S}\")\n",
    "print(f\"Number of Actions (A): {A}\")\n",
    "print(f\"Transition Matrix Train Shape: {transition_matrix_train.shape}\")\n",
    "print(f\"Transition Matrix Test Shape: {transition_matrix_test.shape}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ==============================\n",
    "# 2. Normalize Transition Matrices\n",
    "# ==============================\n",
    "\n",
    "\n",
    "print(\"Normalizing transition matrices...\")\n",
    "transition_matrix_train_normalized = transition_matrix_train.copy()\n",
    "transition_matrix_test_normalized = transition_matrix_test.copy()\n",
    "print(\"Normalization complete.\\n\")\n",
    "\n",
    "# ==============================\n",
    "# 3. Check for NaN Values\n",
    "# ==============================\n",
    "\n",
    "train_nan = np.isnan(transition_matrix_train_normalized).any()\n",
    "test_nan = np.isnan(transition_matrix_test_normalized).any()\n",
    "\n",
    "if train_nan or test_nan:\n",
    "    print(\"NaN values detected in the normalized matrices.\")\n",
    "    # Replace NaNs with zeros\n",
    "    transition_matrix_train_normalized = np.nan_to_num(transition_matrix_train_normalized)\n",
    "    transition_matrix_test_normalized = np.nan_to_num(transition_matrix_test_normalized)\n",
    "    print(\"NaN values have been replaced with zeros.\\n\")\n",
    "else:\n",
    "    print(\"No NaN values detected in the normalized matrices.\\n\")\n",
    "\n",
    "# ==============================\n",
    "# 4. Compute Similarity Metrics\n",
    "# ==============================\n",
    "\n",
    "print(\"Computing similarity metrics...\\n\")\n",
    "\n",
    "frobenius_norms = []\n",
    "js_divergences = []\n",
    "tv_distances = []\n",
    "\n",
    "for a in range(A):\n",
    "    print(f\"Action {a+1}/{A}\")\n",
    "    \n",
    "    # Frobenius Norm\n",
    "    diff = transition_matrix_train_normalized[:, :, a] - transition_matrix_test_normalized[:, :, a]\n",
    "    fro_norm = norm(diff)\n",
    "    frobenius_norms.append(fro_norm)\n",
    "    print(f\"  Frobenius Norm: {fro_norm:.6f}\")\n",
    "    \n",
    "    # Jensen-Shannon Divergence\n",
    "    # Add small epsilon to avoid log(0)\n",
    "    epsilon = 1e-12\n",
    "    p = transition_matrix_train_normalized[:, :, a] + epsilon\n",
    "    q = transition_matrix_test_normalized[:, :, a] + epsilon\n",
    "    \n",
    "    # Re-normalize to ensure rows sum to 1 after epsilon addition\n",
    "    p /= p.sum(axis=0, keepdims=True)\n",
    "    q /= q.sum(axis=0, keepdims=True)\n",
    "    \n",
    "    # Compute JSD for each state\n",
    "    js_div_per_state = []\n",
    "    for s in range(S):\n",
    "        js_div = jensenshannon(p[s], q[s], base=np.e)\n",
    "        js_div_per_state.append(js_div)\n",
    "    average_js_div = np.mean(js_div_per_state)\n",
    "    js_divergences.append(average_js_div)\n",
    "    print(f\"  Average JSD: {average_js_div:.6f}\")\n",
    "    \n",
    "    # Total Variation Distance\n",
    "    tv_per_state = 0.5 * np.sum(np.abs(p - q), axis=0)  # Shape: (S,)\n",
    "    average_tv = np.mean(tv_per_state)\n",
    "    tv_distances.append(average_tv)\n",
    "    print(f\"  Average TV Distance: {average_tv:.6f}\\n\")\n",
    "\n",
    "print(\"Similarity metrics computation complete.\\n\")\n",
    "\n",
    "for a in range(A):\n",
    "    print(f\"Action {a+1}:\")\n",
    "    print(f\"  Frobenius Norm: {frobenius_norms[a]:.6f}\")\n",
    "    print(f\"  Average JSD: {js_divergences[a]:.6f}\")\n",
    "    print(f\"  Average TV Distance: {tv_distances[a]:.6f}\\n\")\n",
    "\n",
    "    \n",
    "from scipy.stats import entropy\n",
    "\n",
    "# Ensure no zeros in the matrices\n",
    "epsilon = 1e-10\n",
    "transition_matrix_train_normalized += epsilon\n",
    "transition_matrix_test_normalized += epsilon\n",
    "\n",
    "kl_divergences = entropy(transition_matrix_train_normalized, transition_matrix_test_normalized, axis=0)\n",
    "average_kl_divergence = np.mean(kl_divergences)\n",
    "print('Average KL Divergence:', average_kl_divergence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f9fd61-3024-4145-8ec3-5adbb62d687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "records.loc[records['action']==-1,'action'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb343c5-3272-4ca0-a73d-361d1037b406",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = records['action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c43db5-cdd7-4fe7-bbd6-555f6cfa7f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if MIMICraw exists\n",
    "if 'MIMICraw' not in globals():\n",
    "    raise NameError(\"MIMICraw DataFrame is not defined. Please load it before merging.\")\n",
    "\n",
    "MIMICraw[records.columns] = records\n",
    "MIMICzs[records.columns] = records\n",
    "\n",
    "full_data_raw = MIMICraw.copy()\n",
    "full_data_zs = MIMICzs.copy()\n",
    "\n",
    "MIMICraw.drop(columns=records.columns, inplace=True)\n",
    "MIMICzs.drop(columns=records.columns, inplace=True)\n",
    "# Validate the merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9693d1-4df3-4dc6-9574-1c0a32b65ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RRT_counts = full_data_raw.groupby('state')['RRT'].value_counts().unstack(fill_value=0).reset_index(drop=True).reset_index(drop=True)\n",
    "\n",
    "# Display the resulting counts\n",
    "print(RRT_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556a188a-b542-4598-83eb-d0dedba7edd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RRT_counts.loc[RRT_counts[1]>5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d27a51-fa52-4f2d-97a5-ac2afff46714",
   "metadata": {},
   "source": [
    "# Action distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc10bb-a1af-4d5c-9ae0-c4a49bd1db53",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_counts = np.bincount(actions, minlength=2)\n",
    "action_percentages = action_counts / len(actions)\n",
    "\n",
    "optimal_actions = model.Q.argmax(axis=1)  # AI's recommended actions\n",
    "optimal_action_counts = np.bincount(optimal_actions, minlength=2)\n",
    "optimal_action_percentages = optimal_action_counts / len(optimal_actions)\n",
    "\n",
    "mortality_rates = []\n",
    "for action_value in [0, 1]:\n",
    "    indices = np.where(actions == action_value)\n",
    "    mortality = outcomes[indices]\n",
    "    mortality_rate = np.mean(mortality)\n",
    "    mortality_rates.append(mortality_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f457e2-3ba9-45d6-85f2-03456ded1ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.font_manager as font_manager\n",
    "\n",
    "# Add every font at the specified location\n",
    "font_dir = ['/home/lkapral/RRT_mimic_iv']\n",
    "for font in font_manager.findSystemFonts(font_dir):\n",
    "    font_manager.fontManager.addfont(font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469fa098-08c5-4514-9ed9-7a948158efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"ticks\", palette=\"pastel\")\n",
    "\n",
    "\n",
    "state_to_optimal_action = {state: action for state, action in enumerate(optimal_actions)}\n",
    "\n",
    "# Apply the mapping to each record's state to get AI's action\n",
    "records['ai_action'] = records['state'].map(state_to_optimal_action)\n",
    "\n",
    "# Validate the mapping\n",
    "if records['ai_action'].isnull().any():\n",
    "    missing_states = records[records['ai_action'].isnull()]['state'].unique()\n",
    "    raise ValueError(f\"Missing optimal actions for states: {missing_states}\")\n",
    "\n",
    "# ------------------------\n",
    "# Step 3: Aggregate Data at Patient Level\n",
    "# ------------------------\n",
    "# Replace action -1 with 0 (assuming -1 represents 'No RRT')\n",
    "records['action'] = records['action'].replace(-1, 0)\n",
    "\n",
    "# Aggregate actions and outcomes at the patient level\n",
    "patient_actions = records.groupby('icustayid').agg({\n",
    "    'action': lambda x: int((x == 1).any()),        # Clinician administered RRT at any time\n",
    "    'ai_action': lambda x: int((x == 1).any()),     # AI recommends RRT at any time\n",
    "    'outcome': 'first'                              # Patient outcome (assumed consistent across time steps)\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "patient_actions.rename(columns={'action': 'clinician_rrt', 'ai_action': 'ai_rrt'}, inplace=True)\n",
    "\n",
    "# ------------------------\n",
    "# Step 4: Compute Action Distributions\n",
    "# ------------------------\n",
    "# Time Steps Action Distribution\n",
    "# Clinician\n",
    "clinician_time_steps_rrt = (records['action'] == 1).sum()\n",
    "total_time_steps = len(records)\n",
    "clinician_time_steps_proportion = clinician_time_steps_rrt / total_time_steps*100\n",
    "\n",
    "# AI\n",
    "ai_time_steps_rrt = (records['ai_action'] == 1).sum()\n",
    "ai_time_steps_proportion = ai_time_steps_rrt / total_time_steps*100\n",
    "\n",
    "# Patient-Level Action Distribution\n",
    "# Clinician\n",
    "clinician_patient_rrt = patient_actions['clinician_rrt'].sum()\n",
    "total_patients = len(patient_actions)\n",
    "clinician_patient_proportion = clinician_patient_rrt / total_patients*100\n",
    "\n",
    "# AI\n",
    "ai_patient_rrt = patient_actions['ai_rrt'].sum()\n",
    "ai_patient_proportion = ai_patient_rrt / total_patients*100\n",
    "\n",
    "# ------------------------\n",
    "# Step 5: Prepare Data for Plotting\n",
    "# ------------------------\n",
    "# Organize the data into a dictionary for easier handling\n",
    "plot_data = {\n",
    "    'Time steps': {\n",
    "        'Clinician-initiated RRT': (clinician_time_steps_proportion, clinician_time_steps_rrt),\n",
    "        'AI-recommended RRT': (ai_time_steps_proportion, ai_time_steps_rrt)\n",
    "    },\n",
    "    'Patients': {\n",
    "        'Clinician-initiated RRT': (clinician_patient_proportion, clinician_patient_rrt),\n",
    "        'AI-recommended RRT': (ai_patient_proportion, ai_patient_rrt)\n",
    "    }\n",
    "}\n",
    "\n",
    "categories = list(plot_data.keys())  # ['Time steps', 'Patients']\n",
    "methods = ['Clinician-initiated RRT', 'AI-recommended RRT']\n",
    "\n",
    "# ------------------------\n",
    "# Step 6: Plot Combined Action Distributions\n",
    "# ------------------------\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "# ------------------------\n",
    "# Set bar width and positions\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(categories))  # [0, 1]\n",
    "\n",
    "# Extract data for plotting\n",
    "clinician_values = [plot_data[cat]['Clinician-initiated RRT'][0] for cat in categories]\n",
    "ai_values = [plot_data[cat]['AI-recommended RRT'][0] for cat in categories]\n",
    "\n",
    "clinician_counts = [plot_data[cat]['Clinician-initiated RRT'][1] for cat in categories]\n",
    "ai_counts = [plot_data[cat]['AI-recommended RRT'][1] for cat in categories]\n",
    "\n",
    "colors = {\n",
    "    \n",
    "    'Clinician-initiated RRT': '#d0d9f0',          # Keeps the calming and professional feel\n",
    "    'AI-recommended RRT': '#6b8ac5'                     # Replaces 'salmon' with a trustworthy color\n",
    "}\n",
    "\n",
    "# Create bars\n",
    "bars1 = ax.bar(index - bar_width/2, clinician_values, bar_width, label='Clinician-initiated RRT', color=colors['Clinician-initiated RRT'])\n",
    "bars2 = ax.bar(index + bar_width/2, ai_values, bar_width, label='AI-recommended RRT', color=colors['AI-recommended RRT'])\n",
    "\n",
    "# Add labels, title, and custom x-axis tick labels\n",
    "ax.set_xlabel('Category')\n",
    "ax.set_ylabel('Proportion of patients receiving RRT (%)')\n",
    "ax.set_xticks(index)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend()\n",
    "\n",
    "# Function to add percentage and count labels on top of each bar\n",
    "def add_percentage_count_labels(bars, counts):\n",
    "    for bar, count in zip(bars, counts):\n",
    "        height = bar.get_height()\n",
    "        # Calculate the position for the annotation\n",
    "        ax.annotate(f'{round(height,1)}%\\nn = {count}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 2),  # 5 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom',\n",
    "                    fontsize=9)\n",
    "\n",
    "# Add percentage and count labels to each bar\n",
    "add_percentage_count_labels(bars1, clinician_counts)\n",
    "add_percentage_count_labels(bars2, ai_counts)\n",
    "\n",
    "# Add grid for better readability\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "# ------------------------\n",
    "# Step 7: Adjust Y-axis Limits to Accommodate Annotations\n",
    "# ------------------------\n",
    "# Find the maximum bar height\n",
    "max_bar = max(max(clinician_values, ai_values))\n",
    "# Set y-axis limit to 1.2 times the maximum bar height or at least 1.0\n",
    "y_max = max_bar * 1.2 if max_bar * 1.2 < 100 else 100\n",
    "\n",
    "ax.set_ylim(0, y_max)\n",
    "\n",
    "\n",
    "# Adjust layout to make room for the annotations\n",
    "plt.tight_layout(rect=[0, 0.25, 1, 0.95])\n",
    "\n",
    "# Change the default font to Helvetica\n",
    "\n",
    "# Step 9: Display the Plot\n",
    "# ------------------------\n",
    "plt.show()\n",
    "\n",
    "# ------------------------\n",
    "fig_path = os.path.join(output_dir, \"evaluation_results\")\n",
    "os.makedirs(fig_path, exist_ok=True)\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig(os.path.join(fig_path, \"mimic_actions_timesteps.png\"), dpi=300)\n",
    "fig.savefig(os.path.join(fig_path, \"mimic_actions_timesteps.eps\"))\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b3224a-28d1-4fb4-a205-ea8b78179cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac304bad-c42d-4933-ab09-34fdf9bf17ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os  # Make sure to import os if not already\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `full_data_raw` is your DataFrame containing the ICU patient data\n",
    "# and `optimal_actions` is a list or array of optimal actions mapped by state.\n",
    "\n",
    "# ===========================\n",
    "# 1. Create a Mapping from State to AI's Optimal Action\n",
    "# ===========================\n",
    "sns.set(style=\"ticks\", palette=\"pastel\")\n",
    "state_to_optimal_action = {state: action for state, action in enumerate(optimal_actions)}\n",
    "\n",
    "# ===========================\n",
    "# 2. Aggregate Data Per Patient to Identify RRT Occurrences\n",
    "# ===========================\n",
    "\n",
    "# Define what constitutes an RRT action\n",
    "# Assuming that 'action' and 'ai_action' are numerical, where >= 0.5 indicates RRT\n",
    "RRT_THRESHOLD = 0.5\n",
    "\n",
    "# First, map AI actions based on state for all records\n",
    "full_data_raw['ai_action'] = full_data_raw['state'].map(state_to_optimal_action)\n",
    "\n",
    "# Validate the mapping\n",
    "if full_data_raw['ai_action'].isnull().any():\n",
    "    missing_states = full_data_raw[full_data_raw['ai_action'].isnull()]['state'].unique()\n",
    "    raise ValueError(f\"Missing optimal actions for states: {missing_states}\")\n",
    "\n",
    "# Identify if RRT was ever performed by Clinicians and AI for each patient\n",
    "patient_rrt = full_data_raw.groupby('icustayid').agg(\n",
    "    clinician_rrt_occurred=('action', lambda x: (x >= RRT_THRESHOLD).any()),\n",
    "    ai_rrt_occurred=('ai_action', lambda x: (x >= RRT_THRESHOLD).any()),\n",
    "    max_SOFA=('SOFA', 'max')\n",
    ").reset_index()\n",
    "\n",
    "# ===========================\n",
    "# 3. Categorize SOFA Scores\n",
    "# ===========================\n",
    "\n",
    "# Define SOFA groups\n",
    "bins = [0, 4, 9, 14, 20]\n",
    "labels = ['0-4 (low)', '5-9 (moderate)', '10-14 (high)', '>15 (very high)']\n",
    "patient_rrt['SOFA_group'] = pd.cut(patient_rrt['max_SOFA'], bins=bins, labels=labels, include_lowest=True)\n",
    "\n",
    "# Handle any SOFA scores outside the defined bins\n",
    "if patient_rrt['SOFA_group'].isnull().any():\n",
    "    print(\"Warning: Some patients have SOFA scores outside the defined bins. These will be excluded from grouping.\")\n",
    "\n",
    "    patient_rrt = patient_rrt.dropna(subset=['SOFA_group'])\n",
    "\n",
    "\n",
    "# Group by SOFA_group and compute proportions and counts\n",
    "action_distributions_sofa = patient_rrt.groupby('SOFA_group').agg(\n",
    "    clinician_rrt_proportion=('clinician_rrt_occurred', 'mean'),\n",
    "    ai_rrt_proportion=('ai_rrt_occurred', 'mean'),\n",
    "    patient_count=('icustayid', 'count')  # Count of patients per SOFA group\n",
    ").reset_index()\n",
    "\n",
    "# Calculate counts for Clinician RRT and AI RRT based on proportions\n",
    "action_distributions_sofa['clinician_rrt_count'] = (action_distributions_sofa['clinician_rrt_proportion'] * action_distributions_sofa['patient_count']).round().astype(int)\n",
    "action_distributions_sofa['ai_rrt_count'] = (action_distributions_sofa['ai_rrt_proportion'] * action_distributions_sofa['patient_count']).round().astype(int)\n",
    "\n",
    "# ===========================\n",
    "# 5. Visualization\n",
    "# ===========================\n",
    "\n",
    "# Parameters for the plot\n",
    "SOFA_groups = action_distributions_sofa['SOFA_group']\n",
    "n_groups = len(SOFA_groups)\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35  # Width of the bars\n",
    "opacity = 0.8\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "# Change the default font to Helvetica\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "# Plotting the \"Clinician-initiated RRT\" and \"AI-recommended RRT\" bars\n",
    "rects1 = ax.bar(index - bar_width/2, action_distributions_sofa['clinician_rrt_proportion']*100,\n",
    "                bar_width, alpha=opacity, color='#d0d9f0', label='Clinican-initiated RRT')\n",
    "\n",
    "rects2 = ax.bar(index + bar_width/2, action_distributions_sofa['ai_rrt_proportion']*100,\n",
    "                bar_width, alpha=opacity, color='#6b8ac5', label='AI-recommended RRT')\n",
    "\n",
    "# Adding labels, title, and custom x-axis tick labels\n",
    "ax.set_xlabel('SOFA Group', fontsize=12)\n",
    "ax.set_ylabel('Proportion of patients receiving RRT (%)', fontsize=12)\n",
    "\n",
    "ax.set_ylim(0, 110)  # Increased to accommodate patient counts\n",
    "\n",
    "# Adding grid lines for better readability\n",
    "ax.yaxis.grid(True, linestyle='--', which='major', color='grey', alpha=0.5)\n",
    "\n",
    "# Removing top and right spines for a cleaner look\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# Adding legend\n",
    "ax.legend()\n",
    "\n",
    "def add_percentage_count_labels(bars, counts):\n",
    "    for bar, count in zip(bars, counts):\n",
    "        height = bar.get_height()\n",
    "        # Calculate the position for the annotation\n",
    "        ax.annotate(f'{round(height,1)}%\\nn = {count}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 2),  # 5 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom',\n",
    "                    fontsize=9)\n",
    "\n",
    "# Apply the function to both sets of bars\n",
    "add_percentage_count_labels(rects1, action_distributions_sofa['clinician_rrt_count'])\n",
    "add_percentage_count_labels(rects2, action_distributions_sofa['ai_rrt_count'])\n",
    "\n",
    "# Modify x-ticks to have only 3 ticks\n",
    "desired_ticks = 4\n",
    "\n",
    "if n_groups > desired_ticks:\n",
    "    # Select first, second, and last tick positions\n",
    "    tick_indices = [0, 1, n_groups - 1]\n",
    "    tick_labels = [SOFA_groups[i] for i in tick_indices]\n",
    "    ax.set_xticks(index[tick_indices])\n",
    "    ax.set_xticklabels(tick_labels, rotation=45, fontsize=10)\n",
    "else:\n",
    "    # If 3 or fewer groups, display all\n",
    "    ax.set_xticks(index)\n",
    "    ax.set_xticklabels(SOFA_groups, rotation=45, fontsize=10)\n",
    "\n",
    "# Improve layout to prevent clipping of tick-labels and annotations\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(os.path.join(fig_path, \"mimic_SOFA_actions.png\"), dpi=300)\n",
    "fig.savefig(os.path.join(fig_path, \"mimic_SOFA_actions.eps\"))\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f263e0-33e2-447e-a70c-b76e1e0dee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze_rrt_by_icu_group(full_data_raw, optimal_actions, icustays_csv_path):\n",
    "    sns.set(style=\"ticks\", palette=\"pastel\")\n",
    "    \"\"\"\n",
    "    Analyze and visualize RRT occurrences by ICU group for Clinician and AI actions.\n",
    "\n",
    "    Parameters:\n",
    "    - full_data_raw (pd.DataFrame): DataFrame containing ICU patient data with columns such as\n",
    "                                     'icustayid', 'state', 'action', 'SOFA', etc.\n",
    "    - optimal_actions (list or np.array): List/array where each index corresponds to a state,\n",
    "                                          representing the AI's optimal action.\n",
    "    - icustays_csv_path (str): File path to the 'icustays.csv' file.\n",
    "\n",
    "    Returns:\n",
    "    - None: Displays a bar plot comparing Clinician and AI-recommended RRT occurrences by ICU group.\n",
    "    \"\"\"\n",
    "    \n",
    "    # ===========================\n",
    "    # 1. Create a Mapping from State to AI's Optimal Action\n",
    "    # ===========================\n",
    "    \n",
    "    # Ensure that 'optimal_actions' is defined and corresponds to all possible states\n",
    "    state_to_optimal_action = {state: action for state, action in enumerate(optimal_actions)}\n",
    "    \n",
    "    # ===========================\n",
    "    # 2. Load and Merge ICU Stays Data\n",
    "    # ===========================\n",
    "    \n",
    "    try:\n",
    "        icustays = pd.read_csv(icustays_csv_path)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"ICU stays data file not found at: {icustays_csv_path}\")\n",
    "    if 'first_careunit' not in( full_data_raw.columns):\n",
    "        # Merge full_data_raw with icustays on 'icustayid' and 'stay_id'\n",
    "        merged = full_data_raw.merge(\n",
    "            icustays[['stay_id', 'first_careunit']],\n",
    "            how='left',\n",
    "            left_on='icustayid',\n",
    "            right_on='stay_id'\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # Assign the 'first_careunit' to full_data_raw\n",
    "        full_data_raw['first_careunit'] = merged['first_careunit']\n",
    "    \n",
    "    # ===========================\n",
    "    # 3. Define and Map ICU Groups\n",
    "    # ===========================\n",
    "    \n",
    "    # Define ICU group mappings\n",
    "    careunit_to_group = {\n",
    "        'Medical Intensive Care Unit (MICU)': 'Medical',\n",
    "        'Coronary Care Unit (CCU)': 'Medical',\n",
    "        'Neuro Intermediate': 'Surgical',\n",
    "        'Medicine': 'Medical',\n",
    "        'Med/Surg': 'Mixed',\n",
    "        'Medicine/Cardiology Intermediate': 'Medical',\n",
    "        'Neurology': 'Surgical',\n",
    "        'Neuro Stepdown': 'Surgical',\n",
    "        'Cardiac Vascular Intensive Care Unit (CVICU)': 'Surgical',\n",
    "        'Surgical Intensive Care Unit (SICU)': 'Surgical',\n",
    "        'Trauma SICU (TSICU)': 'Surgical',\n",
    "        'Neuro Surgical Intensive Care Unit (Neuro SICU)': 'Surgical',\n",
    "        'Surgery/Vascular/Intermediate': 'Mixed',\n",
    "        'PACU': 'Surgical',\n",
    "        'Intensive Care Unit (ICU)': 'Surgical',\n",
    "        'Surgery/Trauma': 'Surgical',\n",
    "        'Medical/Surgical Intensive Care Unit (MICU/SICU)': 'Mixed'\n",
    "    }\n",
    "    \n",
    "    # Map 'first_careunit' to 'ICU_group'\n",
    "    full_data_raw['ICU_group'] = full_data_raw['first_careunit'].map(careunit_to_group)\n",
    "    \n",
    "    # Handle any missing ICU groups\n",
    "    if full_data_raw['ICU_group'].isnull().any():\n",
    "        missing_careunits = full_data_raw[full_data_raw['ICU_group'].isnull()]['first_careunit'].unique()\n",
    "        print(f\"Warning: The following care units are not mapped to an ICU group and will be excluded: {missing_careunits}\")\n",
    "        # Exclude records with unmapped 'first_careunit'\n",
    "        full_data_raw = full_data_raw.dropna(subset=['ICU_group'])\n",
    "    \n",
    "    # ===========================\n",
    "    # 4. Map States to AI Actions\n",
    "    # ===========================\n",
    "    \n",
    "    # Map the state to AI's action for all records\n",
    "    full_data_raw['ai_action'] = full_data_raw['state'].map(state_to_optimal_action)\n",
    "    \n",
    "    # Validate the mapping\n",
    "    if full_data_raw['ai_action'].isnull().any():\n",
    "        missing_states = full_data_raw[full_data_raw['ai_action'].isnull()]['state'].unique()\n",
    "        raise ValueError(f\"Missing optimal actions for states: {missing_states}\")\n",
    "    \n",
    "    # ===========================\n",
    "    # 5. Aggregate Data Per Patient to Identify RRT Occurrences\n",
    "    # ===========================\n",
    "    \n",
    "    # Identify if RRT was ever performed by Clinicians and AI for each patient\n",
    "    patient_rrt = full_data_raw.groupby('icustayid').agg(\n",
    "        clinician_rrt_occurred=('action', lambda x: (x == 1).any()),\n",
    "        ai_rrt_occurred=('ai_action', lambda x: (x == 1).any()),\n",
    "        ICU_group=('ICU_group', 'first')  # Assuming ICU_group is consistent per patient\n",
    "    ).reset_index()\n",
    "    \n",
    "    # ===========================\n",
    "    # 6. Compute Action Distributions and Patient Counts\n",
    "    # ===========================\n",
    "    \n",
    "    # Group by ICU_group and compute proportions and counts\n",
    "    action_distributions_icu = patient_rrt.groupby('ICU_group').agg(\n",
    "        clinician_rrt_proportion=('clinician_rrt_occurred', 'mean'),\n",
    "        ai_rrt_proportion=('ai_rrt_occurred', 'mean'),\n",
    "        patient_count=('icustayid', 'count')  # Count of patients per ICU group\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Calculate counts for Clinician-initiated RRT and AI-recommended RRT based on proportions\n",
    "    action_distributions_icu['clinician_rrt_count'] = (action_distributions_icu['clinician_rrt_proportion'] * action_distributions_icu['patient_count']).round().astype(int)\n",
    "    action_distributions_icu['ai_rrt_count'] = (action_distributions_icu['ai_rrt_proportion'] * action_distributions_icu['patient_count']).round().astype(int)\n",
    "    \n",
    "    # ===========================\n",
    "    # 7. Visualization\n",
    "    # ===========================\n",
    "    \n",
    "    # Parameters for the plot\n",
    "    ICU_groups = action_distributions_icu['ICU_group']\n",
    "    n_groups = len(ICU_groups)\n",
    "    index = np.arange(n_groups)\n",
    "    bar_width = 0.35  # Width of the bars\n",
    "    opacity = 0.8\n",
    "    \n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    # Change the default font to Helvetica\n",
    "    plt.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "    \n",
    "    rects1 = ax.bar(index - bar_width/2, action_distributions_icu['clinician_rrt_proportion']*100,\n",
    "                    bar_width, alpha=opacity, color='#d0d9f0', label='Clinician-initiated RRT')\n",
    "    \n",
    "    rects2 = ax.bar(index + bar_width/2, action_distributions_icu['ai_rrt_proportion']*100,\n",
    "                    bar_width, alpha=opacity, color='#6b8ac5', label='AI-recommended RRT')\n",
    "    \n",
    "    # Adding labels, title, and custom x-axis tick labels\n",
    "    ax.set_xlabel('ICU Group', fontsize=12)\n",
    "    ax.set_ylabel('Proportion of patients receiving RRT (%)', fontsize=12)\n",
    "\n",
    "    ax.set_xticklabels(ICU_groups, rotation=45, fontsize=10)\n",
    "    ax.set_ylim(0, 15)  # Increased to accommodate patient counts\n",
    "    \n",
    "    # Adding grid lines for better readability\n",
    "    ax.yaxis.grid(True, linestyle='--', which='major', color='grey', alpha=0.5)\n",
    "    \n",
    "    # Removing top and right spines for a cleaner look\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    desired_ticks = 3\n",
    "    \n",
    "    if n_groups > desired_ticks:\n",
    "        # Select first, second, and last tick positions\n",
    "        tick_indices = [0, 1, n_groups - 1]\n",
    "        tick_labels = [ICU_groups[i] for i in tick_indices]\n",
    "        ax.set_xticks(index[tick_indices])\n",
    "        ax.set_xticklabels(tick_labels, rotation=45, fontsize=10)\n",
    "    else:\n",
    "        # If 3 or fewer groups, display all\n",
    "        ax.set_xticks(index)\n",
    "        ax.set_xticklabels(ICU_groups, rotation=45, fontsize=10)\n",
    "        \n",
    "        # Adding legend\n",
    "        ax.legend()\n",
    "    \n",
    "    def add_percentage_count_labels(bars, counts):\n",
    "        for bar, count in zip(bars, counts):\n",
    "            height = bar.get_height()\n",
    "            # Calculate the position for the annotation\n",
    "            ax.annotate(f'{round(height,1)}%\\nn = {count}',\n",
    "                        xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                        xytext=(0, 2),  # 5 points vertical offset\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom',\n",
    "                        fontsize=9)\n",
    "    \n",
    "    # Apply the function to both sets of bars\n",
    "    add_percentage_count_labels(rects1, action_distributions_icu['clinician_rrt_count'])\n",
    "    add_percentage_count_labels(rects2, action_distributions_icu['ai_rrt_count'])\n",
    "    \n",
    "    # Improve layout to prevent clipping of tick-labels and annotations\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "    fig.savefig(os.path.join(fig_path, \"mimic_ICU_actions.png\"), dpi=300)\n",
    "    fig.savefig(os.path.join(fig_path, \"mimic_ICU_actions.eps\"))\n",
    "\n",
    "    return action_distributions_icu\n",
    "\n",
    "    \n",
    "# Mock icustays.csv DataFrame\n",
    "careunits = [\n",
    "    'Medical Intensive Care Unit (MICU)', 'Coronary Care Unit (CCU)',\n",
    "    'Neuro Intermediate', 'Medicine', 'Med/Surg', 'Medicine/Cardiology Intermediate',\n",
    "    'Neurology', 'Neuro Stepdown', 'Cardiac Vascular Intensive Care Unit (CVICU)',\n",
    "    'Surgical Intensive Care Unit (SICU)', 'Trauma SICU (TSICU)',\n",
    "    'Neuro Surgical Intensive Care Unit (Neuro SICU)', 'Surgery/Vascular/Intermediate',\n",
    "    'PACU', 'Intensive Care Unit (ICU)', 'Surgery/Trauma',\n",
    "    'Medical/Surgical Intensive Care Unit (MICU/SICU)'\n",
    "]\n",
    "\n",
    "icu_stay_id_dir = '/home/lkapral/RRT_mimic_iv/data/icustays.csv'\n",
    "# ===========================\n",
    "# 2. Execute the Analysis Function\n",
    "# ===========================\n",
    "\n",
    "action_distributions_icu =analyze_rrt_by_icu_group(full_data_raw, optimal_actions, icu_stay_id_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6335ae21-f082-4148-9ce5-330c2bc5cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_counts = np.bincount(actions, minlength=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d9bbe7-ec4f-494c-8fff-1ea1b8c28a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "df = full_data_raw\n",
    "\n",
    "# Group where action is at least 1\n",
    "action_at_least_1 = df[df['action'] >= 1].groupby('icustayid')['bloc'].max().reset_index()\n",
    "action_at_least_1['group'] = 'at_least_1'\n",
    "\n",
    "# Group where action is always 0\n",
    "action_always_0 = df.groupby('icustayid').filter(lambda x: (x['action'] == 0).all())\n",
    "action_always_0 = action_always_0.groupby('icustayid')['bloc'].max().reset_index()\n",
    "action_always_0['group'] = 'always_0'\n",
    "\n",
    "# Combine both groups into a single DataFrame for comparison\n",
    "comparison_df = pd.concat([action_at_least_1, action_always_0])\n",
    "\n",
    "# Optional: Pivot for easier comparison\n",
    "pivot_df = comparison_df.pivot(index='icustayid', columns='group', values='bloc')\n",
    "\n",
    "print(pivot_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b700c599-f175-4de7-afbb-db5bfb4de0b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_patients = full_data_raw.groupby('icustayid')['bloc'].max().reset_index()\n",
    "all_patients['group'] = 'always_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7f86c9-3534-4701-ab2c-0bffef965cd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_patients.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fffdf8-429c-441c-bf47-de5253b6d01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute AI bot's recommended actions\n",
    "optimal_actions = model.Q.argmax(axis=1)  # Optimal action per state\n",
    "\n",
    "# Map states to AI bot's recommended actions\n",
    "ai_recommended_actions = optimal_actions[states]\n",
    "\n",
    "# Determine concordance\n",
    "concordant = (actions == ai_recommended_actions).astype(int)\n",
    "\n",
    "# Calculate concordance rate\n",
    "concordance_rate = np.mean(concordant)\n",
    "print(f\"Concordance Rate between clinician and AI bot: {concordance_rate:.2%}\")\n",
    "\n",
    "# Add concordance information to records\n",
    "records['concordant'] = concordant\n",
    "\n",
    "# Visualize Concordance Distribution\n",
    "fig_concordance = plt.figure(figsize=(8, 6))\n",
    "concordance_counts = np.bincount(concordant, minlength=2)\n",
    "concordance_percentages = concordance_counts / len(concordant)\n",
    "\n",
    "plot_concordance = concordance_percentages.copy()\n",
    "plot_concordance[0] = concordance_percentages[1]\n",
    "plot_concordance[1] = concordance_percentages[0]\n",
    "\n",
    "plt.bar(['Concordant', 'Non-Concordant'], plot_concordance, color=['teal', 'red'])\n",
    "plt.ylabel('Proportion')\n",
    "plt.title('Concordance between Clinician and AI Bot Actions')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b63fe68-6f3b-45da-91f1-56524f22f0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the aesthetic style of the plots\n",
    "sns.set(style=\"ticks\", palette=\"pastel\")\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "# ------------------------\n",
    "# Step 1: Aggregate All Necessary Data\n",
    "# ------------------------\n",
    "\n",
    "# Assuming you have already performed the following aggregations:\n",
    "# 1. Time Steps Action Distribution (clinician_time_steps_proportion, ai_time_steps_proportion)\n",
    "# 2. Patient-Level Action Distribution (clinician_patient_proportion, ai_patient_proportion)\n",
    "# 3. SOFA Groups Action Distribution (action_distributions_sofa)\n",
    "# 4. ICU Groups Action Distribution (action_distributions_icu)\n",
    "\n",
    "# For demonstration, let's create mock data structures based on your provided code.\n",
    "\n",
    "# 1. Time Steps\n",
    "time_steps_data = {\n",
    "    'Category': ['Time steps'] * 2,\n",
    "    'Method': ['Clinician-initiated RRT', 'AI-recommended RRT'],\n",
    "    'Proportion': [clinician_time_steps_proportion, ai_time_steps_proportion],\n",
    "    'Count': [clinician_time_steps_rrt, ai_time_steps_rrt]\n",
    "}\n",
    "\n",
    "# 2. Patients\n",
    "patients_data = {\n",
    "    'Category': ['Patients'] * 2,\n",
    "    'Method': ['Clinician-initiated RRT', 'AI-recommended RRT'],\n",
    "    'Proportion': [clinician_patient_proportion, ai_patient_proportion],\n",
    "    'Count': [clinician_patient_rrt, ai_patient_rrt]\n",
    "}\n",
    "\n",
    "# 3. SOFA Groups\n",
    "# Assuming 'action_distributions_sofa' DataFrame from SOFA analysis\n",
    "# with columns: 'SOFA_group', 'clinician_rrt_proportion', 'ai_rrt_proportion', 'clinician_rrt_count', 'ai_rrt_count'\n",
    "\n",
    "sofa_groups = action_distributions_sofa['SOFA_group'].tolist()\n",
    "sofa_proportions_clinician = (action_distributions_sofa['clinician_rrt_proportion'] * 100).tolist()\n",
    "sofa_proportions_ai = (action_distributions_sofa['ai_rrt_proportion'] * 100).tolist()\n",
    "sofa_counts_clinician = action_distributions_sofa['clinician_rrt_count'].tolist()\n",
    "sofa_counts_ai = action_distributions_sofa['ai_rrt_count'].tolist()\n",
    "\n",
    "sofa_data = {\n",
    "    'Category': sofa_groups * 2,\n",
    "    'Method': ['Clinician-initiated RRT'] * len(sofa_groups) + ['AI-recommended RRT'] * len(sofa_groups),\n",
    "    'Proportion': sofa_proportions_clinician + sofa_proportions_ai,\n",
    "    'Count': sofa_counts_clinician + sofa_counts_ai\n",
    "}\n",
    "\n",
    "# 4. ICU Groups\n",
    "# Assuming 'action_distributions_icu' DataFrame from ICU analysis\n",
    "# with columns: 'ICU_group', 'clinician_rrt_proportion', 'ai_rrt_proportion', 'clinician_rrt_count', 'ai_rrt_count'\n",
    "\n",
    "icu_groups = action_distributions_icu['ICU_group'].tolist()\n",
    "icu_proportions_clinician = (action_distributions_icu['clinician_rrt_proportion'] * 100).tolist()\n",
    "icu_proportions_ai = (action_distributions_icu['ai_rrt_proportion'] * 100).tolist()\n",
    "icu_counts_clinician = action_distributions_icu['clinician_rrt_count'].tolist()\n",
    "icu_counts_ai = action_distributions_icu['ai_rrt_count'].tolist()\n",
    "\n",
    "icu_data = {\n",
    "    'Category': icu_groups * 2,\n",
    "    'Method': ['Clinician-initiated RRT'] * len(icu_groups) + ['AI-recommended RRT'] * len(icu_groups),\n",
    "    'Proportion': icu_proportions_clinician + icu_proportions_ai,\n",
    "    'Count': icu_counts_clinician + icu_counts_ai\n",
    "}\n",
    "\n",
    "# Combine all data into a single DataFrame\n",
    "# To ensure SOFA comes after ICU, concatenate in the desired order\n",
    "combined_data = pd.concat([\n",
    "    pd.DataFrame(time_steps_data),\n",
    "    pd.DataFrame(patients_data),\n",
    "    pd.DataFrame(icu_data),\n",
    "    pd.DataFrame(sofa_data)\n",
    "], ignore_index=True)\n",
    "\n",
    "# ------------------------\n",
    "# Step 2: Plot the Combined Bar Chart\n",
    "# ------------------------\n",
    "\n",
    "# Define the desired order of categories\n",
    "# Remove 'sorted()' to maintain the original order of ICU and SOFA groups\n",
    "desired_order = ['Patients', 'Time steps'] + icu_groups + sofa_groups\n",
    "\n",
    "# Reorder the combined_data DataFrame\n",
    "combined_data['Category'] = pd.Categorical(combined_data['Category'], categories=desired_order, ordered=True)\n",
    "combined_data = combined_data.sort_values('Category')\n",
    "\n",
    "# Determine unique categories and methods\n",
    "unique_categories = combined_data['Category'].cat.categories\n",
    "unique_methods = combined_data['Method'].unique()\n",
    "\n",
    "# Number of categories and methods\n",
    "n_categories = len(unique_categories)\n",
    "n_methods = len(unique_methods)\n",
    "\n",
    "# Define bar width and positions\n",
    "bar_width = 0.35\n",
    "index = np.arange(n_categories)\n",
    "\n",
    "# Initialize the plot\n",
    "fig, ax = plt.subplots(figsize=(16, 10))  # Adjust figsize as needed\n",
    "\n",
    "# Define colors for each method\n",
    "colors = {\n",
    "    'Clinician-initiated RRT': '#d0d9f0',\n",
    "    'AI-recommended RRT': '#6b8ac5'\n",
    "}\n",
    "\n",
    "# Plot each method\n",
    "for i, method in enumerate(unique_methods):\n",
    "    # Extract proportions and counts for the current method\n",
    "    proportions = combined_data[combined_data['Method'] == method]['Proportion'].values\n",
    "    counts = combined_data[combined_data['Method'] == method]['Count'].values\n",
    "    \n",
    "    # Calculate bar positions\n",
    "    # Center the bars around each category index\n",
    "    bar_positions = index + (i - n_methods / 2) * bar_width + bar_width / 2\n",
    "    \n",
    "    # Create bars\n",
    "    bars = ax.bar(bar_positions, proportions, bar_width, label=method, color=colors.get(method, '#333333'),  edgecolor='black', linewidth=1 )\n",
    "    \n",
    "    # Add annotations\n",
    "    for bar, count in zip(bars, counts):\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{round(height,1)}%\\nn = {count}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom',\n",
    "                    fontsize=9)\n",
    "\n",
    "# Set y-axis label\n",
    "ax.set_ylabel('Proportion of RRT (%)', fontsize=14)\n",
    "\n",
    "# Set x-axis labels and positions\n",
    "ax.set_xticks(index)\n",
    "ax.set_xticklabels(unique_categories, rotation=45, ha='center', fontsize=10)  # Reduced fontsize to 10\n",
    "\n",
    "# Add legend\n",
    "ax.legend()\n",
    "\n",
    "# Add grid for y-axis\n",
    "ax.yaxis.grid(True, linestyle='--', which='major', color='grey', alpha=0.5)\n",
    "\n",
    "# Adjust y-axis limits to accommodate annotations\n",
    "y_max = combined_data['Proportion'].max() * 1.12 if combined_data['Proportion'].max() * 1.12 < 100 else 100\n",
    "ax.set_ylim(0, y_max)\n",
    "\n",
    "# ------------------------\n",
    "# Step 3: Add Group Labels Above Categories\n",
    "# ------------------------\n",
    "\n",
    "# Define the main groups and their corresponding categories\n",
    "# Order adjusted to reflect the desired group names and their categories\n",
    "main_groups = {\n",
    "    'Patients': ['Patients'],\n",
    "    'Time steps': ['Time steps'],\n",
    "    'Patients (ICU groups)': icu_groups,\n",
    "    'Patients (SOFA groups)': sofa_groups\n",
    "}\n",
    "\n",
    "# Calculate the starting and ending indices for each main group\n",
    "group_boundaries = {}\n",
    "current_start = 0\n",
    "for group, categories in main_groups.items():\n",
    "    num_categories = len(categories)\n",
    "    group_boundaries[group] = (current_start, current_start + num_categories - 1)\n",
    "    current_start += num_categories\n",
    "\n",
    "# Add group labels\n",
    "for group, (start, end) in group_boundaries.items():\n",
    "    # Calculate the center position\n",
    "    center = (start + end) / 2\n",
    "    # Adjust the y position based on y_max\n",
    "    y_pos = y_max * 0.95  # Positioned near the top of the plot\n",
    "    # Add text\n",
    "    ax.text(center, y_pos, group, ha='center', va='bottom', fontsize=16, fontweight='bold', color='black')\n",
    "\n",
    "# Optional: Add spacing above the plot for group labels\n",
    "plt.subplots_adjust(top=0.85)  # Adjusted to provide more space if needed\n",
    "\n",
    "# ------------------------\n",
    "# Step 4: Add Three Vertical Dotted Lines Between Groups\n",
    "# ------------------------\n",
    "\n",
    "# Define the positions where the vertical lines should be placed\n",
    "# After 'Time Steps', after 'Patients', and after 'ICU Groups'\n",
    "\n",
    "# Calculate the number of categories in each main group\n",
    "counts = [len(categories) for categories in main_groups.values()]\n",
    "\n",
    "# Cumulative sum to find the end of each group\n",
    "cumulative_counts = np.cumsum(counts)\n",
    "\n",
    "# The vertical lines should be placed between groups, i.e., at positions cumulative_counts[:-1]\n",
    "# Since each category is centered at index positions, the lines should be placed at cumulative_counts - 0.5\n",
    "separator_positions = cumulative_counts[:-1] - 0.5\n",
    "\n",
    "# Add vertical dotted lines\n",
    "for pos in separator_positions:\n",
    "    ax.axvline(x=pos, linestyle='--', color='grey', alpha=0.7)\n",
    "\n",
    "# ------------------------\n",
    "# Step 5: Improve X-axis Labels (Wrapping Long Labels)\n",
    "# ------------------------\n",
    "\n",
    "# If labels are too long, consider abbreviating or wrapping them\n",
    "# For example, using multi-line labels\n",
    "\n",
    "def wrap_label(label, width=15):\n",
    "    if len(label) > width:\n",
    "        return '\\n'.join([label[i:i+width] for i in range(0, len(label), width)])\n",
    "    else:\n",
    "        return label\n",
    "\n",
    "# Apply label wrapping\n",
    "wrapped_labels = [wrap_label(label) for label in unique_categories]\n",
    "ax.set_xticklabels(wrapped_labels, rotation=45, ha='center', fontsize=10)  # fontsize reduced to 10\n",
    "\n",
    "# ------------------------\n",
    "# Step 6: Final Adjustments and Layout\n",
    "# ------------------------\n",
    "\n",
    "# Tight layout to prevent clipping\n",
    "plt.tight_layout()\n",
    "\n",
    "# ------------------------\n",
    "# Step 7: Save and Display the Plot\n",
    "# ------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save the figure in desired formats\n",
    "fig.savefig(os.path.join(fig_path, \"combined_mimic_actions.png\"), dpi=300, bbox_inches='tight')\n",
    "fig.savefig(os.path.join(fig_path, \"combined_mimic_actions.eps\"), bbox_inches='tight' )\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f7f7fc-dafc-4e8f-bdf8-8350d62c69bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "separator_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ababe71-796e-4fdf-b455-562b4260951c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b730a0f-619d-4465-b3b0-b66c2bd2b5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge MIMICraw and metadata on index or a common key\n",
    "merged_df = full_data_raw\n",
    "\n",
    "# Now, 'icustayid' and 'action' are both in merged_df\n",
    "# Identify patients who received RRT\n",
    "rrt_patients = merged_df.loc[merged_df['action'] == 1, C_ICUSTAYID].unique()\n",
    "\n",
    "if len(rrt_patients) > 0:\n",
    "    # Select an example patient\n",
    "    example_patient_id = np.random.choice(rrt_patients)\n",
    "    print(f\"Selected Example Patient ICU Stay ID: {example_patient_id}\")\n",
    "\n",
    "    # Extract patient data\n",
    "    patient_data = merged_df[merged_df[C_ICUSTAYID] == example_patient_id].copy()\n",
    "\n",
    "    # Get time steps\n",
    "    time_steps = patient_data[C_BLOC].values\n",
    "\n",
    "    # Clinician's actions\n",
    "    clinician_actions = patient_data['action'].values\n",
    "\n",
    "    # States\n",
    "    patient_indices = merged_df[C_ICUSTAYID] == example_patient_id\n",
    "    patient_states = states[patient_indices]\n",
    "\n",
    "    # AI bot's recommended actions\n",
    "    ai_actions = optimal_actions[patient_states]\n",
    "\n",
    "    # Plot clinician vs. AI actions over time\n",
    "    fig_patient = plt.figure(figsize=(12, 6))\n",
    "    plt.step(time_steps, clinician_actions, label='Clinician Action', where='post')\n",
    "    plt.step(time_steps, ai_actions, label='AI Bot Recommended Action', where='post', linestyle='--')\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Action (0: No RRT, 1: RRT)')\n",
    "    plt.title(f'Clinician vs. AI Actions for Patient {example_patient_id}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Optionally, plot key physiological variables (e.g., 'Creatinine')\n",
    "    if 'Creatinine' in patient_data.columns:\n",
    "        fig_creatinine = plt.figure(figsize=(12, 6))\n",
    "        plt.plot(time_steps, patient_data['Creatinine'], label='Creatinine Level', marker='o')\n",
    "        plt.xlabel('Time Step')\n",
    "        plt.ylabel('Creatinine Level')\n",
    "        plt.title(f'Creatinine Levels Over Time for Patient {example_patient_id}')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No patients with RRT found in the dataset.\")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf63e49-f3af-4438-bd6f-bef4fa3ce03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "ax.yaxis.grid(True, linestyle='--', which='major', color='grey', alpha=0.5)\n",
    "# Group 1: Patients who received RRT as per clinician\n",
    "clinician_rrt_indices = np.where(actions == 1)[0]\n",
    "clinician_rrt_mortality = outcomes[clinician_rrt_indices]\n",
    "clinician_rrt_mortality_rate = np.mean(clinician_rrt_mortality)\n",
    "print(f\"Clinician-initiated RRT Mortality Rate: {clinician_rrt_mortality_rate:.2%}\")\n",
    "\n",
    "# Group 2: Patients who would receive RRT as per AI bot\n",
    "ai_rrt_indices = np.where(ai_recommended_actions == 1)[0]\n",
    "ai_rrt_mortality = outcomes[ai_rrt_indices]\n",
    "ai_rrt_mortality_rate = np.mean(ai_rrt_mortality)\n",
    "print(f\"AI Bot RRT Mortality Rate: {ai_rrt_mortality_rate:.2%}\")\n",
    "\n",
    "# Statistical Test\n",
    "# Prepare contingency table\n",
    "clinician_rrt_deaths = np.sum(clinician_rrt_mortality)\n",
    "clinician_rrt_survivors = len(clinician_rrt_mortality) - clinician_rrt_deaths\n",
    "ai_rrt_deaths = np.sum(ai_rrt_mortality)\n",
    "ai_rrt_survivors = len(ai_rrt_mortality) - ai_rrt_deaths\n",
    "\n",
    "contingency_table = np.array([\n",
    "    [clinician_rrt_deaths, clinician_rrt_survivors],\n",
    "    [ai_rrt_deaths, ai_rrt_survivors]\n",
    "])\n",
    "\n",
    "chi2, p_value, _, _ = chi2_contingency(contingency_table)\n",
    "print(f\"Chi-squared Test: chi2 = {chi2:.4f}, p-value = {p_value:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Visualization\n",
    "fig_mortality = plt.figure(figsize=(8, 6))\n",
    "mortality_rates = [clinician_rrt_mortality_rate, ai_rrt_mortality_rate]\n",
    "labels = ['Clinician-initiated RRT', 'AI Bot RRT']\n",
    "plt.bar(labels, mortality_rates, color=['#6b8ac5', '#0c385c'])\n",
    "plt.ylabel('Mortality Rate')\n",
    "plt.title('Mortality Rates of Patients Receiving RRT')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80234f31-d472-46f5-8b6a-68c894150052",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Get unique states\n",
    "# unique_states = np.unique(states)\n",
    "\n",
    "# # Initialize lists to store proportions\n",
    "# clinician_action_proportions = []\n",
    "# ai_action_proportions = []\n",
    "\n",
    "# for state in unique_states:\n",
    "#     # Clinician actions in this state\n",
    "#     clinician_actions_in_state = actions[states == state]\n",
    "#     clinician_action_counts = np.bincount(clinician_actions_in_state, minlength=2)\n",
    "#     total_clinician_actions = clinician_action_counts.sum()\n",
    "#     if total_clinician_actions > 0:\n",
    "#         clinician_action_prop = clinician_action_counts / total_clinician_actions\n",
    "#     else:\n",
    "#         clinician_action_prop = np.array([0, 0])  # Or np.nan, depending on preference\n",
    "#     clinician_action_proportions.append(clinician_action_prop)\n",
    "    \n",
    "#     # AI actions in this state\n",
    "#     ai_actions_in_state = ai_recommended_actions[states == state]\n",
    "#     ai_action_counts = np.bincount(ai_actions_in_state, minlength=2)\n",
    "#     total_ai_actions = ai_action_counts.sum()\n",
    "#     if total_ai_actions > 0:\n",
    "#         ai_action_prop = ai_action_counts / total_ai_actions\n",
    "#     else:\n",
    "#         ai_action_prop = np.array([0, 0])\n",
    "#     ai_action_proportions.append(ai_action_prop)\n",
    "\n",
    "# # Convert to arrays\n",
    "# clinician_action_proportions = np.array(clinician_action_proportions)\n",
    "# ai_action_proportions = np.array(ai_action_proportions)\n",
    "\n",
    "# # Plotting\n",
    "# num_states = len(unique_states)\n",
    "# num_cols = 5  # You can adjust this as needed\n",
    "# num_rows = int(np.ceil(num_states / num_cols))\n",
    "\n",
    "# fig_state_actions = plt.figure(figsize=(3 * num_cols, 3 * num_rows))\n",
    "\n",
    "# for idx, state in enumerate(unique_states):\n",
    "#     plt.subplot(num_rows, num_cols, idx + 1)\n",
    "#     bar_width = 0.35\n",
    "#     index = np.arange(2)\n",
    "    \n",
    "#     # Plot clinician action proportions\n",
    "#     plt.bar(index, clinician_action_proportions[idx], bar_width, label='Clinician')\n",
    "#     # Plot AI action proportions\n",
    "#     plt.bar(index + bar_width, ai_action_proportions[idx], bar_width, label='AI Bot')\n",
    "    \n",
    "#     plt.title(f'State {state}', fontsize=10)\n",
    "#     plt.xticks(index + bar_width / 2, ['No RRT', 'RRT'], fontsize=8)\n",
    "#     plt.yticks(fontsize=8)\n",
    "#     plt.ylim(0, 1)\n",
    "    \n",
    "#     # Add legend only once\n",
    "#     if idx == 0:\n",
    "#         plt.legend(fontsize=8)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139b7c23-0882-4e8c-a5c2-9d6af9339f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812b6975-5b07-4e2c-b7a5-d05f7fc010b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIMICraw[metadata.columns] = metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd394606-fe2b-44e7-94aa-974a915d5d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dad1b6-e240-4164-840e-be9f0d25ecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.plotting import add_at_risk_counts\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# --- Data Preparation ---\n",
    "\n",
    "# Assuming all necessary data are already defined:\n",
    "# model, stay_ids, actions, states, blocs, metadata, outcomes, full_data_raw, C_ICUSTAYID, fig_path\n",
    "\n",
    "# 1. Compute AI's actions for each state\n",
    "optimal_actions = model.Q.argmax(axis=1)\n",
    "\n",
    "# 2. Use the new grouping approach based on full_data_raw:\n",
    "#    Identify if RRT was ever performed by Clinicians and suggested by the AI for each patient.\n",
    "patient_rrt = full_data_raw.groupby('icustayid').agg(\n",
    "    clinician_rrt_occurred=('action', lambda x: (x == 1).any()),\n",
    "    ai_rrt_occurred=('ai_action', lambda x: (x == 1).any()),\n",
    ").reset_index()\n",
    "\n",
    "# Remove any potential NaN values after mapping\n",
    "confusion_data = patient_rrt.dropna(subset=['ai_rrt_occurred', 'clinician_rrt_occurred'])\n",
    "\n",
    "# Create a confusion matrix comparing clinician and AI RRT flags.\n",
    "# Convert boolean flags to integers for the confusion_matrix function.\n",
    "cm = confusion_matrix(\n",
    "    confusion_data['clinician_rrt_occurred'].astype(int), \n",
    "    confusion_data['ai_rrt_occurred'].astype(int), \n",
    "    labels=[1, 0]\n",
    ")\n",
    "\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, \n",
    "    index=['Clinician: RRT', 'Clinician: No RRT'], \n",
    "    columns=['AI: RRT', 'AI: No RRT']\n",
    ")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_df)\n",
    "\n",
    "# Define patient groups based on whether each party ever performed/suggested RRT.\n",
    "def get_group(row):\n",
    "    if row['ai_rrt_occurred'] and row['clinician_rrt_occurred']:\n",
    "        return 'Both RRT'\n",
    "    elif row['ai_rrt_occurred'] and not row['clinician_rrt_occurred']:\n",
    "        return 'AI-recommended RRT only'\n",
    "    elif not row['ai_rrt_occurred'] and row['clinician_rrt_occurred']:\n",
    "        return 'Clinician-initiated RRT only'\n",
    "    else:\n",
    "        return 'Neither RRT'\n",
    "    \n",
    "patient_rrt['group'] = patient_rrt.apply(get_group, axis=1)\n",
    "\n",
    "# 3. Calculate Maximum Bloc per Patient (time to event or censoring)\n",
    "max_bloc_per_patient = pd.Series(blocs).groupby(stay_ids).max().reset_index()\n",
    "max_bloc_per_patient.columns = [C_ICUSTAYID, 'max_bloc']\n",
    "\n",
    "# 4. Determine Global Maximum Bloc (for censoring patients without an event)\n",
    "global_max_bloc = max_bloc_per_patient['max_bloc'].max()\n",
    "print(f\"Global Maximum Bloc: {global_max_bloc}\")\n",
    "\n",
    "# 5. Assign Survival Time and Event Status\n",
    "#    Create a dictionary mapping each ICUSTAY_ID to the event (death = 1, survival = 0).\n",
    "patient_events = {}\n",
    "unique_patients = np.unique(stay_ids)\n",
    "for icustay_id in unique_patients:\n",
    "    event_indices = np.where(metadata[C_ICUSTAYID] == icustay_id)[0]\n",
    "    if len(event_indices) > 0:\n",
    "        event = outcomes[event_indices[0]]  # 1 if death occurred, 0 if not\n",
    "        patient_events[icustay_id] = event\n",
    "    else:\n",
    "        patient_events[icustay_id] = np.nan  # Handle missing data appropriately\n",
    "\n",
    "# 6. Merge Data into a Single DataFrame for Survival Analysis\n",
    "survival_data = pd.DataFrame({\n",
    "    C_ICUSTAYID: unique_patients,\n",
    "    'event': [patient_events[id_] for id_ in unique_patients]\n",
    "})\n",
    "\n",
    "# Merge the maximum bloc per patient\n",
    "survival_data = survival_data.merge(max_bloc_per_patient, on=C_ICUSTAYID, how='left')\n",
    "\n",
    "# Merge in the patient group information from our new grouping (patient_rrt)\n",
    "# Make sure the grouping DataFrame has the same patient identifier column name.\n",
    "survival_data = survival_data.merge(patient_rrt[[C_ICUSTAYID, 'group']], left_on=C_ICUSTAYID, right_on='icustayid', how='left')\n",
    "#survival_data.drop(columns='icustayid', inplace=True)  # Remove duplicate column if present\n",
    "\n",
    "# 7. Remove Patients with Missing Events or Group Assignments\n",
    "survival_data = survival_data.dropna(subset=['event', 'group'])\n",
    "\n",
    "# 8. Assign Survival Time Based on Event Status\n",
    "#    If event = 1 (death), use the patient's max_bloc; else, assign a censoring time (e.g., 180 blocs)\n",
    "survival_data['survival_time'] = np.where(\n",
    "    survival_data['event'] == 1,\n",
    "    survival_data['max_bloc'],\n",
    "    180\n",
    ")\n",
    "\n",
    "# Convert survival_time from blocs to days (assuming 1 bloc = 0.5 days; adjust if necessary)\n",
    "survival_data['time_days'] = survival_data['survival_time'] * 0.5\n",
    "\n",
    "# 9. Merge additional patient information (e.g., 'SOFA' and 'age') from full_data_raw.\n",
    "#    Aggregation here assumes these values remain constant per patient.\n",
    "patient_severity = full_data_raw.groupby(C_ICUSTAYID).agg({\n",
    "    'age': 'first',   # Use 'first' if age is constant; otherwise, adjust as needed.\n",
    "    'SOFA': 'first'   # Similarly, adjust for SOFA scores if needed.\n",
    "}).reset_index()\n",
    "\n",
    "survival_data = survival_data.merge(patient_severity, on=C_ICUSTAYID, how='left')\n",
    "\n",
    "# 10. Remove Patients with Missing Severity Data\n",
    "survival_data = survival_data.dropna(subset=['age', 'SOFA'])\n",
    "\n",
    "# 11. Define Group Order and Convert 'group' to a Categorical Type\n",
    "group_order = ['AI-recommended RRT only', 'Both RRT', 'Clinician-initiated RRT only', 'Neither RRT']\n",
    "survival_data['group'] = pd.Categorical(survival_data['group'], categories=group_order, ordered=True)\n",
    "\n",
    "# At this point, survival_data is ready for further analysis (e.g., Kaplan-Meier survival analysis)\n",
    "print(\"Survival data head:\")\n",
    "print(survival_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdb871f-667d-4686-897a-b6155546aa7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fe1e28-348e-4c36-9a50-177ad79173cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.drop_duplicates(subset=['icustayid'])['outcome'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5b35a7-f965-466e-b882-6704aa4645d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lifelines import KaplanMeierFitter\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "# Assuming 'survival_data', 'group_order', and 'fig_path' are already defined\n",
    "\n",
    "# 1. Define a More Distinct Color Mapping Using Seaborn's Color Palette\n",
    "color_mapping = {\n",
    "    'Neither RRT': 'olive',\n",
    "    'AI-recommended RRT only': '#6b8ac5',\n",
    "    'Both RRT': 'salmon',\n",
    "    'Clinician-initiated RRT only': '#d0d9f0'\n",
    "}\n",
    "\n",
    "CI_mapping = {\n",
    "    'Neither RRT': True,\n",
    "    'AI-recommended RRT only': True,\n",
    "    'Both RRT': True,\n",
    "    'Clinician-initiated RRT only': True\n",
    "}\n",
    "\n",
    "# 1.a. Calculate Group Sizes and Mortality Rates\n",
    "group_sizes = survival_data.groupby('group').size()\n",
    "event_counts = survival_data.groupby('group')['event'].sum()\n",
    "mortality_rates = (event_counts / group_sizes) * 100  # Percentage\n",
    "\n",
    "# 2. Initialize the Plot with Broken Axes\n",
    "sns.set(style=\"ticks\")\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "# Adjust the width of the plots to ensure equal day representation\n",
    "left_days = 11  # Range for the first plot\n",
    "right_days = 4  # Range for the second plot (85 to 90)\n",
    "\n",
    "# The width ratio is proportional to the day ranges\n",
    "fig, (ax1, ax2) = plt.subplots(\n",
    "    1, 2, \n",
    "    sharey=True, \n",
    "    figsize=(14, 7),\n",
    "    gridspec_kw={'width_ratios': [left_days, right_days]}\n",
    ")\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.subplots_adjust(wspace=0.05)\n",
    "\n",
    "# 3. Fit and Plot Kaplan-Meier Curves for Each Group with Enhanced Styling\n",
    "kmf_list = []\n",
    "line_styles = ['-', '-', '-', '-']\n",
    "\n",
    "for idx, group in enumerate(group_order):\n",
    "    ix = survival_data['group'] == group\n",
    "    kmf = KaplanMeierFitter()\n",
    "    kmf.fit(\n",
    "        durations=survival_data.loc[ix, 'time_days'],\n",
    "        event_observed=survival_data.loc[ix, 'event'],\n",
    "        label=group\n",
    "    )\n",
    "    \n",
    "    color = color_mapping.get(group, 'gray')\n",
    "    linestyle = line_styles[idx % len(line_styles)]\n",
    "    ci = CI_mapping.get(group, True)\n",
    "    \n",
    "    # Plot on the left axis\n",
    "    kmf.plot_survival_function(\n",
    "        ax=ax1,\n",
    "        ci_show=ci,\n",
    "        color=color,\n",
    "        alpha=1,\n",
    "        ci_alpha=0.2,\n",
    "        linewidth=2.5,\n",
    "        linestyle=linestyle\n",
    "    )\n",
    "    \n",
    "    # Plot on the right axis\n",
    "    kmf.plot_survival_function(\n",
    "        ax=ax2,\n",
    "        ci_show=ci,\n",
    "        color=color,\n",
    "        alpha=1,\n",
    "        ci_alpha=0.2,\n",
    "        linewidth=2.5,\n",
    "        linestyle=linestyle\n",
    "    )\n",
    "    \n",
    "    kmf_list.append(kmf)\n",
    "    \n",
    "    # 3.a. Annotate Mortality Rates on the Right Plot\n",
    "    # Positioning the text at the end of the survival curve in the right plot\n",
    "    # We'll estimate the survival probability at the maximum x-limit of the right plot\n",
    "    max_day_right = ax2.get_xlim()[1]\n",
    "    survival_at_max = kmf.survival_function_at_times(max_day_right).values[0]\n",
    "    mortality_rate = mortality_rates[group]\n",
    "    \n",
    "    # Adjust the y-position slightly based on survival probability to avoid overlap\n",
    "\n",
    "    y_position = survival_at_max + 0.01 if survival_at_max + 0.01 < 1 else survival_at_max - 0.01\n",
    "    ax2.text(\n",
    "        max_day_right - 8,  # Slightly to the right of the plot\n",
    "        y_position,\n",
    "        f\"Mortaltity rate: {mortality_rate:.1f}%\",\n",
    "        color='black',\n",
    "        fontsize=10,\n",
    "        verticalalignment='center',\n",
    "        horizontalalignment='left'\n",
    "    )\n",
    "\n",
    "# 4. Customize Each Subplot\n",
    "\n",
    "# --- Left Plot: 0 to 12 Days ---\n",
    "ax1.set_xlim(0, 11)\n",
    "ax1.set_xlabel('Time (days)', fontsize=14)\n",
    "ax1.set_ylabel('Survival probability', fontsize=14)\n",
    "ax1.set_ylim([0.30, 1.01])\n",
    "\n",
    "# --- Right Plot: 85 to 90 Days ---\n",
    "ax2.set_xlim(86, 90)\n",
    "ax2.set_xlabel('', fontsize=14)\n",
    "ax2.set_ylim([0.30, 1.01])\n",
    "\n",
    "# 5. Add Connection Arrows to Indicate Broken Axis\n",
    "d = .015  # size of diagonal lines in axes coordinates\n",
    "kwargs = dict(transform=ax1.transAxes, color='k', clip_on=False)\n",
    "ax1.plot((1 - d, 1 + d), (-d, +d), **kwargs)\n",
    "ax1.plot((1 - d, 1 + d), (1 - d, 1 + d), **kwargs)\n",
    "\n",
    "kwargs.update(transform=ax2.transAxes)\n",
    "ax2.plot((-d, +d), (-d, +d), **kwargs)\n",
    "ax2.plot((-d, +d), (1 - d, 1 + d), **kwargs)\n",
    "\n",
    "# 6. Place Legend Only on the Left Plot with Number of Patients\n",
    "# Modify legend labels to include the number of patients\n",
    "legend_labels = [f\"{group} (n={group_sizes[group]})\" for group in group_order]\n",
    "handles, _ = ax1.get_legend_handles_labels()\n",
    "# Update the legend with new labels\n",
    "ax1.legend(handles, legend_labels,fontsize=10, title_fontsize=12)\n",
    "\n",
    "ax2.legend().set_visible(False)\n",
    "# 7. Enhance Grid for Better Readability\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.grid(\n",
    "        which='major', \n",
    "        linestyle='--', \n",
    "        color='grey', \n",
    "        alpha=0.2,  # More visible grid\n",
    "        linewidth=1\n",
    "    )\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(2))  # Tick every 2 days\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "# 8. Increase Tick Parameters for Better Readability\n",
    "ax1.tick_params(axis='both', which='major', labelsize=10)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save the plot in specified formats\n",
    "os.makedirs(fig_path, exist_ok=True)\n",
    "fig.savefig(\n",
    "    os.path.join(fig_path, \"mimic_survival_plot_km_custom_equal_days.png\"), \n",
    "    dpi=300\n",
    ")\n",
    "fig.savefig(\n",
    "    os.path.join(fig_path, \"mimic_survival_plot_km_custom_equal_days.eps\")\n",
    ")\n",
    "\n",
    "# Close the Figure to Free Memory\n",
    "plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3152ddc0-3e15-475d-86c7-0a09de27d191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00060c83-0c06-482e-82bd-4e6f985396a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from lifelines import CoxPHFitter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# Identify if RRT was ever performed by Clinicians and AI for each patient\n",
    "patient_rrt = full_data_raw.groupby('icustayid').agg(\n",
    "    clinician_rrt_occurred=('action', lambda x: (x == 1).any()),\n",
    "    ai_rrt_occurred=('ai_action', lambda x: (x == 1).any()),\n",
    ").reset_index()\n",
    "\n",
    "# Remove any potential NaN values after mapping\n",
    "confusion_data = patient_rrt.dropna(subset=['ai_rrt_occurred', 'clinician_rrt_occurred'])\n",
    "\n",
    "cm = confusion_matrix(\n",
    "    confusion_data['clinician_rrt_occurred'], \n",
    "    confusion_data['ai_rrt_occurred'], \n",
    "    labels=[1, 0]\n",
    ")\n",
    "\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, \n",
    "    index=['Clinician: RRT', 'Clinician: No RRT'], \n",
    "    columns=['AI: RRT', 'AI: No RRT']\n",
    ")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_df)\n",
    "\n",
    "# Desired alpha\n",
    "desired_alpha = 0.8\n",
    "\n",
    "# Function to convert hex colors to RGBA with given alpha\n",
    "def hex_to_rgba(hex_color, alpha=1.0):\n",
    "    hex_color = hex_color.strip('#')\n",
    "    r = int(hex_color[0:2], 16) / 255.0\n",
    "    g = int(hex_color[2:4], 16) / 255.0\n",
    "    b = int(hex_color[4:6], 16) / 255.0\n",
    "    return (r, g, b, alpha)\n",
    "\n",
    "# Predefine some colors in hex\n",
    "hex_colors = {\n",
    "    'Neither RRT': 'C0C0C0',           # silver\n",
    "    'AI-recommended RRT only': '6b8ac5',\n",
    "    'Both RRT': '000000',         # black\n",
    "    'Clinician-initiated RRT only': 'd0d9f0'\n",
    "}\n",
    "\n",
    "# Convert to RGBA with desired alpha\n",
    "rgba_colors = {\n",
    "    'Neither RRT': hex_to_rgba(hex_colors['Neither RRT'], desired_alpha),\n",
    "    'AI-recommended RRT only': hex_to_rgba(hex_colors['AI-recommended RRT only'], desired_alpha),\n",
    "    'Both RRT': hex_to_rgba(hex_colors['Both RRT'], desired_alpha),\n",
    "    'Clinician-initiated RRT only': hex_to_rgba(hex_colors['Clinician-initiated RRT only'], desired_alpha)\n",
    "}\n",
    "\n",
    "# Updated color mapping for the confusion matrix cells\n",
    "color_mapping = {\n",
    "    ('Clinician: RRT', 'AI: RRT'): rgba_colors['Both RRT'],               # Both RRT\n",
    "    ('Clinician: RRT', 'AI: No RRT'): rgba_colors['Clinician-initiated RRT only'],  # Clinician-initiated RRT only\n",
    "    ('Clinician: No RRT', 'AI: RRT'): rgba_colors['AI-recommended RRT only'],         # AI-recommended RRT only\n",
    "    ('Clinician: No RRT', 'AI: No RRT'): rgba_colors['Neither RRT']            # No RRT\n",
    "}\n",
    "\n",
    "# Create a color matrix\n",
    "cell_colors = []\n",
    "for row in cm_df.index:\n",
    "    row_colors = []\n",
    "    for col in cm_df.columns:\n",
    "        color = color_mapping.get((row, col), (1, 1, 1, 1))\n",
    "        row_colors.append(color)\n",
    "    cell_colors.append(row_colors)\n",
    "\n",
    "cell_colors = np.array(cell_colors)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "sns.set(style=\"ticks\", palette=\"pastel\")\n",
    "ax.yaxis.grid(False)\n",
    "ax.xaxis.grid(False)\n",
    "\n",
    "for i in range(cm_df.shape[0]):\n",
    "    for j in range(cm_df.shape[1]):\n",
    "        cell_color = cell_colors[i, j]\n",
    "        ax.add_patch(plt.Rectangle((j, i), 1, 1, color=cell_color))\n",
    "\n",
    "        # Determine text color based on brightness\n",
    "        r, g, b, a = cell_color\n",
    "        brightness = (0.299*r + 0.587*g + 0.114*b)\n",
    "        text_color = 'white' if brightness < 0.5 else 'black'\n",
    "\n",
    "        ax.text(\n",
    "            j + 0.5, i + 0.5, int(cm_df.iloc[i, j]),\n",
    "            ha='center', va='center', color=text_color, fontsize=16\n",
    "        )\n",
    "\n",
    "ax.set_xlim(0, cm_df.shape[1])\n",
    "ax.set_ylim(cm_df.shape[0], 0)\n",
    "ax.set_xticks(np.arange(cm_df.shape[1]) + 0.5)\n",
    "ax.set_yticks(np.arange(cm_df.shape[0]) + 0.5)\n",
    "ax.set_xticklabels(cm_df.columns, fontsize=12)\n",
    "ax.set_yticklabels(cm_df.index, fontsize=12)\n",
    "plt.xlabel('AI-recommended RRT', fontsize=14)\n",
    "plt.ylabel('Clinician-initiated RRT', fontsize=14)\n",
    "\n",
    "\n",
    "# Updated legend using the rgba colors\n",
    "legend_elements = [\n",
    "    Patch(facecolor=rgba_colors['Both RRT'],             edgecolor='black', label='Both RRT'),\n",
    "    Patch(facecolor=rgba_colors['Clinician-initiated RRT only'],   edgecolor='black', label='Clinician-initiated RRT only'),\n",
    "    Patch(facecolor=rgba_colors['AI-recommended RRT only'],          edgecolor='black', label='AI-recommended RRT only'),\n",
    "    Patch(facecolor=rgba_colors['Neither RRT'],               edgecolor='black', label='Neither RRT')\n",
    "]\n",
    "\n",
    "ax.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(1.45, 1))\n",
    "\n",
    "plt.show()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save as PNG with high resolution\n",
    "fig.savefig(\n",
    "    os.path.join(fig_path, \"mimic_confusion_matrix.png\"),\n",
    "    dpi=300,\n",
    "    bbox_inches='tight'  # Ensures all elements are included\n",
    ")\n",
    "\n",
    "# Save as EPS\n",
    "fig.savefig(\n",
    "    os.path.join(fig_path, \"mimic_confusion_matrix.eps\"),\n",
    "    bbox_inches='tight'  # Ensures all elements are included\n",
    ")\n",
    "\n",
    "plt.close(fig)\n",
    "\n",
    "# Compute classification metrics\n",
    "y_true = confusion_data['clinician_rrt_occurred']\n",
    "y_pred = confusion_data['ai_rrt_occurred']\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall (Sensitivity): {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5668bb-06db-4ac5-bbd1-e4f95f434623",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Category 1: Clinician performed RRT, AI did not ('Clinician: RRT', 'AI: No RRT')\n",
    "clinician_rrt_ai_no_rrt = confusion_data[\n",
    "    (confusion_data['clinician_rrt_occurred'] == True) &\n",
    "    (confusion_data['ai_rrt_occurred'] == False)\n",
    "]['icustayid']\n",
    "\n",
    "# Save to CSV\n",
    "clinician_rrt_ai_no_rrt.to_csv(\n",
    "    os.path.join(data_dir, \"mimic_clinician_rrt_ai_no_rrt.csv\"),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(f\"Saved {len(clinician_rrt_ai_no_rrt)} icustayids to 'clinician_rrt_ai_no_rrt.csv'.\")\n",
    "\n",
    "# Category 2: Clinician did not perform RRT, AI did ('Clinician: No RRT', 'AI: RRT')\n",
    "clinician_no_rrt_ai_rrt = confusion_data[\n",
    "    (confusion_data['clinician_rrt_occurred'] == False) &\n",
    "    (confusion_data['ai_rrt_occurred'] == True)\n",
    "]['icustayid']\n",
    "\n",
    "# Save to CSV\n",
    "clinician_no_rrt_ai_rrt.to_csv(\n",
    "    os.path.join(data_dir, \"mimic_clclinician_no_rrt_ai_rrt.csv\"),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(f\"Saved {len(clinician_no_rrt_ai_rrt)} icustayids to 'clinician_no_rrt_ai_rrt.csv'.\")\n",
    "\n",
    "# Category 3: Clinician did not perform RRT, AI did ('Clinician: No RRT', 'AI: No RRT')\n",
    "clinician_no_rrt_no_ai_rrt = confusion_data[\n",
    "    (confusion_data['clinician_rrt_occurred'] == False) &\n",
    "    (confusion_data['ai_rrt_occurred'] == False)\n",
    "]['icustayid']\n",
    "\n",
    "# Save to CSV\n",
    "clinician_no_rrt_no_ai_rrt.to_csv(\n",
    "    os.path.join(data_dir, \"mimic_clclinician_no_rrt_ai_no_rrt.csv\"),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(f\"Saved {len(clinician_no_rrt_no_ai_rrt)} icustayids to 'clinician_no_rrt_no_ai_rrt.csv'.\")\n",
    "\n",
    "# Category 4: Clinician did not perform RRT, AI did ('Clinician: No RRT', 'AI: RRT')\n",
    "clinician_rrt_ai_rrt = confusion_data[\n",
    "    (confusion_data['clinician_rrt_occurred'] == True) &\n",
    "    (confusion_data['ai_rrt_occurred'] == True)\n",
    "]['icustayid']\n",
    "\n",
    "# Save to CSV\n",
    "clinician_rrt_ai_rrt.to_csv(\n",
    "    os.path.join(data_dir, \"mimic_clclinician_rrt_ai_rrt.csv\"),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(f\"Saved {len(clinician_rrt_ai_rrt)} icustayids to 'clinician_rrt_ai_rrt.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6538e5f5-11ac-4289-932e-090d791b5261",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_recommended_actions.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366e852f-c696-4f3a-863b-2500e11af698",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ai_recommended_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3c575d-fa2f-4e11-9d09-06b9799e564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIMICraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddee8bd-19d4-42d9-a4cd-d185f572de4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensure seaborn aesthetics are set\n",
    "sns.set(style=\"whitegrid\", palette=\"pastel\")\n",
    "\n",
    "def plot_violin(data, labels, variable, title, palette, figsize=(12, 6)):\n",
    "    \"\"\"\n",
    "    Plots a violin plot for the given data.\n",
    "\n",
    "    Parameters:\n",
    "    - data: List of pandas Series.\n",
    "    - labels: List of group labels.\n",
    "    - variable: The variable name (string) to plot.\n",
    "    - title: The title of the plot.\n",
    "    - palette: Dictionary mapping group labels to colors.\n",
    "    - figsize: Tuple for figure size.\n",
    "    \"\"\"\n",
    "    # Combine data into a single DataFrame\n",
    "    df_plot = pd.DataFrame({\n",
    "        variable: np.concatenate(data),\n",
    "        'Group': np.repeat(labels, [len(d) for d in data])\n",
    "    })\n",
    "\n",
    "    # Initialize the matplotlib figure\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    # Create the violin plot\n",
    "    sns.violinplot(x='Group', y=variable, data=df_plot, palette=palette, inner='quartile')\n",
    "\n",
    "    # Enhance plot aesthetics\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "    plt.ylabel(variable, fontsize=12)\n",
    "    plt.xlabel('Action Groups', fontsize=12)\n",
    "    plt.title(title, fontsize=14, weight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Define the variables to plot\n",
    "variables_to_plot = ['Creatinine', 'output_step']\n",
    "\n",
    "# Define the color palette\n",
    "custom_palette = {\n",
    "    'Clinician No RRT': 'skyblue',\n",
    "    'Clinician-initiated RRT': 'skyblue',\n",
    "    'AI No RRT': 'teal',\n",
    "    'AI-recommended RRT': 'teal'\n",
    "}\n",
    "\n",
    "for variable in variables_to_plot:\n",
    "    # Check if the variable exists in MIMICraw\n",
    "    if variable in MIMICraw.columns:\n",
    "        # Create groups\n",
    "        clinician_no_rrt = MIMICraw.loc[actions == 0, variable].dropna()\n",
    "        clinician_rrt = MIMICraw.loc[actions == 1, variable].dropna()\n",
    "        ai_no_rrt = MIMICraw.loc[ai_recommended_actions == 0, variable].dropna()\n",
    "        ai_rrt = MIMICraw.loc[ai_recommended_actions == 1, variable].dropna()\n",
    "        \n",
    "        # Prepare data and labels\n",
    "        data = [clinician_no_rrt, clinician_rrt, ai_no_rrt, ai_rrt]\n",
    "        labels = ['Clinician No RRT', 'Clinician-initiated RRT', 'AI No RRT', 'AI-recommended RRT']\n",
    "        \n",
    "        # Define the plot title\n",
    "        plot_title = f'Distribution of {variable} by Action Groups'\n",
    "        \n",
    "        # Plot the violin plot\n",
    "        plot_violin(\n",
    "            data=data,\n",
    "            labels=labels,\n",
    "            variable=variable,\n",
    "            title=plot_title,\n",
    "            palette=custom_palette,\n",
    "            figsize=(14, 7)\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Variable '{variable}' not found in MIMICraw.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9a51e1-775d-4889-b9b6-230a4376c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clinician's actions\n",
    "clinician_action_matrix = np.zeros((n_cluster_states, n_actions))\n",
    "for state in range(n_cluster_states):\n",
    "    state_actions = actions[states == state]\n",
    "    action_counts = np.bincount(state_actions, minlength=n_actions)\n",
    "    clinician_action_matrix[state, :] = action_counts / action_counts.sum() if action_counts.sum() > 0 else 0\n",
    "\n",
    "# AI bot's recommended actions\n",
    "ai_action_matrix = np.zeros((n_cluster_states, n_actions))\n",
    "for state in range(n_cluster_states):\n",
    "    state_ai_actions = ai_recommended_actions[states == state]\n",
    "    action_counts = np.bincount(state_ai_actions, minlength=n_actions)\n",
    "    ai_action_matrix[state, :] = action_counts / action_counts.sum() if action_counts.sum() > 0 else 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a329dd3-4ad3-4f2f-8407-c8aa84dcc477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute difference in action proportions between clinician and AI for each state\n",
    "action_diff = np.abs(clinician_action_matrix - ai_action_matrix).sum(axis=1)\n",
    "\n",
    "# Get indices of states with the largest differences\n",
    "top_n = 20  # Adjust as needed\n",
    "top_states_indices = np.argsort(action_diff)[-top_n:]\n",
    "\n",
    "# Extract action frequencies for these states\n",
    "top_clinician_actions = clinician_action_matrix[top_states_indices, :]\n",
    "top_ai_actions = ai_action_matrix[top_states_indices, :]\n",
    "\n",
    "# Plot heatmaps for the selected states\n",
    "fig_heatmaps = plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Clinician's heatmap\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(top_clinician_actions, cmap='Blues', annot=True, fmt=\".2f\", yticklabels=top_states_indices)\n",
    "plt.title('Clinician Action Frequencies (Top Differences)')\n",
    "plt.xlabel('Action')\n",
    "plt.ylabel('State')\n",
    "\n",
    "# AI bot's heatmap\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(top_ai_actions, cmap='Greens', annot=True, fmt=\".2f\", yticklabels=top_states_indices)\n",
    "plt.title('AI Bot Recommended Action Frequencies (Top Differences)')\n",
    "plt.xlabel('Action')\n",
    "plt.ylabel('State')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63605898-45bb-4a98-8038-8c40d5b09f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.express as px\n",
    "\n",
    "# Assuming you have MIMICzs, actions, ai_recommended_actions defined\n",
    "# Here we assume:\n",
    "# - 0 means \"No RRT\"\n",
    "# - 1 means \"RRT\"\n",
    "\n",
    "sample_size = 10000\n",
    "N = len(MIMICzs)\n",
    "if N > sample_size:\n",
    "    sampled_indices = np.random.choice(MIMICzs.index, sample_size, replace=False)\n",
    "    MIMICzs_sampled = MIMICzs.iloc[sampled_indices] if isinstance(MIMICzs, pd.DataFrame) else MIMICzs[sampled_indices]\n",
    "    actions_sampled = actions.iloc[sampled_indices] if isinstance(actions, pd.Series) else np.array(actions)[sampled_indices]\n",
    "    ai_actions_sampled = ai_recommended_actions.iloc[sampled_indices] if isinstance(ai_recommended_actions, pd.Series) else np.array(ai_recommended_actions)[sampled_indices]\n",
    "else:\n",
    "    MIMICzs_sampled = MIMICzs\n",
    "    actions_sampled = actions\n",
    "    ai_actions_sampled = ai_recommended_actions\n",
    "\n",
    "# Map 0 -> \"No RRT\" and 1 -> \"RRT\"\n",
    "actions_sampled = np.where(np.array(actions_sampled) == 1, 'RRT', 'No RRT')\n",
    "ai_actions_sampled = np.where(np.array(ai_actions_sampled) == 1, 'RRT', 'No RRT')\n",
    "\n",
    "# Convert to string and strip whitespace (just to be safe)\n",
    "actions_sampled = pd.Series([str(a).strip() for a in actions_sampled])\n",
    "ai_actions_sampled = pd.Series([str(a).strip() for a in ai_actions_sampled])\n",
    "\n",
    "# Print unique values to ensure they contain both 'RRT' and 'No RRT'\n",
    "print(\"Unique clinician_action values:\", actions_sampled.unique())\n",
    "print(\"Unique ai_action values:\", ai_actions_sampled.unique())\n",
    "\n",
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "state_embeddings = tsne.fit_transform(\n",
    "    MIMICzs_sampled.values if isinstance(MIMICzs_sampled, pd.DataFrame) else MIMICzs_sampled\n",
    ")\n",
    "\n",
    "embedding_df = pd.DataFrame({\n",
    "    'x': state_embeddings[:, 0],\n",
    "    'y': state_embeddings[:, 1],\n",
    "    'z': state_embeddings[:, 2],\n",
    "    'clinician_action': actions_sampled.values,\n",
    "    'ai_action': ai_actions_sampled.values\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "# Create a combined category\n",
    "def categorize(row):\n",
    "    c_action = row['clinician_action']\n",
    "    ai_action = row['ai_action']\n",
    "    if c_action == 'No RRT' and ai_action == 'No RRT':\n",
    "        return 'Neither RRT'\n",
    "    elif c_action == 'No RRT' and ai_action == 'RRT':\n",
    "        return 'AI-recommended RRT only'\n",
    "    elif c_action == 'RRT' and ai_action == 'RRT':\n",
    "        return 'Both RRT'\n",
    "    elif c_action == 'RRT' and ai_action == 'No RRT':\n",
    "        return 'Clinician-initiated RRT only'\n",
    "    else:\n",
    "        return 'No RRT'\n",
    "\n",
    "embedding_df['combined_category'] = embedding_df.apply(categorize, axis=1)\n",
    "\n",
    "# Print counts of each category to confirm distribution\n",
    "print(\"Category counts:\\n\", embedding_df['combined_category'].value_counts())\n",
    "\n",
    "# Define color map\n",
    "color_mapping = {\n",
    "    'Neither RRT': 'olive',           # silver\n",
    "    'AI-recommended RRT only': '#6b8ac5',\n",
    "    'Both RRT': 'salmon',         # black\n",
    "    'Clinician-initiated RRT only': '#d0d9f0'\n",
    "}\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    embedding_df,\n",
    "    x='x', y='y', z='z',\n",
    "    color='combined_category',\n",
    "    color_discrete_map=color_mapping,\n",
    "    hover_data=['clinician_action', 'ai_action'],\n",
    "    title='3D t-SNE of Patient States - Single Interactive Plot (Color by Combined Category)'\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=5, opacity=0.7, line=dict(width=1, color='DarkSlateGrey')))\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "# Increase figure size\n",
    "fig.update_layout(\n",
    "    width=1600,  # Width in pixels\n",
    "    height=1000, # Height in pixels\n",
    "    legend_title_text='Category'\n",
    ")\n",
    "\n",
    "# Save the figure as an HTML file you can open in a browser\n",
    "fig.write_html(os.path.join(fig_path,\"mimic_tsne_3d_interactive_colormap.html\"))\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cb696e-9818-4323-aa5c-08ba876112a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8236efdd-a282-4eed-8fa3-1c9b21035cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Comprehensive Code for Discrepancy Analysis Between Clinician and AI Recommendations Using Random Forest (n_estimators=200) ---\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "# --- Step 1: Data Preparation ---\n",
    "\n",
    "# Assuming the following variables are predefined and loaded:\n",
    "# - full_data_raw: DataFrame containing merged MIMIC data with clinician actions, 'icustayid', and 'bloc'\n",
    "# - metadata: DataFrame containing 'bloc', 'icustayid', 'outcome' columns\n",
    "# - ai_recommended_actions: List or array of AI recommended actions aligned with 'full_data_raw'\n",
    "# - states: List or array of state assignments corresponding to 'icustayid's in 'full_data_raw'\n",
    "# - stay_ids: List or array of 'icustayid's corresponding to the 'states' array\n",
    "# - reduced_features: List of feature column names to be used in the analysis\n",
    "\n",
    "# Merge 'state_df' into 'merged_data' on 'icustayid'\n",
    "merged_data = full_data_raw.copy()\n",
    "\n",
    "# Create a DataFrame mapping 'icustayid' to 'state'\n",
    "state_df = pd.DataFrame({\n",
    "    'icustayid': stay_ids,\n",
    "    'state': states\n",
    "})\n",
    "\n",
    "# Drop duplicates in 'state_df' if any\n",
    "state_df = state_df.drop_duplicates(subset='icustayid')\n",
    "\n",
    "# Merge 'state_df' into 'merged_data' on 'icustayid'\n",
    "merged_data = merged_data.merge(state_df, on='icustayid', how='left')\n",
    "\n",
    "# Ensure 'ai_recommended_actions' is a list or array with the same length as 'merged_data'\n",
    "if len(ai_recommended_actions) != len(merged_data):\n",
    "    raise ValueError(f\"'ai_recommended_actions' length ({len(ai_recommended_actions)}) does not match 'merged_data' length ({len(merged_data)}).\")\n",
    "merged_data['ai_recommended_actions'] = ai_recommended_actions\n",
    "\n",
    "# --- Step 2: Create Discrepancy Indicator ---\n",
    "\n",
    "# Create discrepancy indicator where 1 indicates a discrepancy between clinician and AI actions\n",
    "merged_data['action_discrepancy'] = (merged_data['action'] != merged_data['ai_recommended_actions']).astype(int)\n",
    "\n",
    "# --- Step 3: Prepare Data for Analysis ---\n",
    "\n",
    "# Define patient features\n",
    "patient_features = reduced_features.copy()\n",
    "\n",
    "# --- Handling Categorical Variables (e.g., 'gender') ---\n",
    "\n",
    "if 'gender' in merged_data.columns:\n",
    "    # Encode categorical variables using one-hot encoding\n",
    "    merged_data = pd.get_dummies(merged_data, columns=['gender'], drop_first=True)\n",
    "    \n",
    "    # Update 'patient_features' to include encoded gender variable(s)\n",
    "    # Remove 'gender' from patient_features if it exists and add the encoded columns\n",
    "    patient_features = [col for col in patient_features if col != 'gender'] + [col for col in merged_data.columns if col.startswith('gender_')]\n",
    "else:\n",
    "    print(\"No 'gender' column found in merged_data. Skipping gender encoding.\")\n",
    "\n",
    "# --- Step 4: Define Target Variable ---\n",
    "\n",
    "# Define target variable representing discrepancy\n",
    "y_discrepancy = merged_data['action_discrepancy']\n",
    "\n",
    "# Define features (X)\n",
    "X = merged_data[patient_features]\n",
    "\n",
    "# --- Step 5: Handle Missing Values ---\n",
    "\n",
    "# Check for missing values in X\n",
    "print(\"Missing values in each feature before handling missing data:\")\n",
    "print(X.isnull().sum())\n",
    "\n",
    "# Impute missing values using mean strategy for numerical features\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# --- Step 6: Perform Random Forest Modeling (n_estimators=200) ---\n",
    "\n",
    "def compute_feature_importance_rf(X, y, feature_names, n_estimators=200, random_state=42):\n",
    "    \"\"\"\n",
    "    Fits a Random Forest model and returns feature importances.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: Features DataFrame\n",
    "    - y: Target variable\n",
    "    - feature_names: List of feature names\n",
    "    - n_estimators: Number of trees in the forest\n",
    "    - random_state: Seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    - feature_importance: DataFrame with feature importances\n",
    "    - model: Trained Random Forest model\n",
    "    - scaler: Fitted StandardScaler\n",
    "    - X_test_scaled: Scaled test features\n",
    "    - y_test: Test target\n",
    "    \"\"\"\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Initialize and fit Random Forest model with n_estimators=200\n",
    "    rf = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state, class_weight='balanced')\n",
    "    rf.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = rf.feature_importances_\n",
    "    \n",
    "    # Create DataFrame for feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importances\n",
    "    })\n",
    "    \n",
    "    # Sort features by importance\n",
    "    feature_importance = feature_importance.sort_values(by='importance', ascending=False)\n",
    "    \n",
    "    return feature_importance, rf, scaler, X_test_scaled, y_test\n",
    "\n",
    "# Compute feature importance for Discrepancy\n",
    "discrepancy_importance, rf_discrepancy, scaler_discrepancy, X_test_discrepancy, y_test_discrepancy = compute_feature_importance_rf(\n",
    "    X_imputed, y_discrepancy, X.columns, n_estimators=200, random_state=42\n",
    ")\n",
    "\n",
    "# Display feature importances\n",
    "print(\"\\nFeature Importances from Random Forest Model (n_estimators=200):\")\n",
    "print(discrepancy_importance)\n",
    "\n",
    "# --- Step 7: Feature Importance Comparison ---\n",
    "\n",
    "# Since we're only modeling discrepancy directly, we have one set of importances.\n",
    "# To compare Clinician and AI, we need separate models or a different approach.\n",
    "# However, as per your latest instruction, we'll focus on the most important features in general.\n",
    "\n",
    "# Calculate top 10 most important features based on importance\n",
    "top_n_general = 10\n",
    "top_general_features = discrepancy_importance.head(top_n_general)['feature'].tolist()\n",
    "\n",
    "# Identify remaining features\n",
    "remaining_features = discrepancy_importance[~discrepancy_importance['feature'].isin(top_general_features)]\n",
    "\n",
    "# Calculate disparity: Since we have only one model, disparity needs a different approach.\n",
    "# Assuming that previously we had separate models for Clinician and AI, but as per latest instruction,\n",
    "# it's unclear. Alternatively, we can assume \"disparity\" refers to features that are important but not in top general.\n",
    "# However, given only one set of importances, disparity is not directly measurable.\n",
    "# To fulfill the request, I'll assume that disparity was previously computed or needs to be computed differently.\n",
    "\n",
    "# Since the user requested to plot the top 10 by average importance and then the 5 with most disparity not in top 10,\n",
    "# but with only one set of importances, we need to proceed accordingly.\n",
    "# Therefore, to maintain consistency with previous steps where we had importances for Clinician and AI,\n",
    "# I'll proceed assuming that both importances are available.\n",
    "\n",
    "# However, in the current code, we have only one set of importances.\n",
    "# To proceed, let's modify the code to train two separate models: one for Clinician alignment and one for AI alignment.\n",
    "\n",
    "# --- Additional Step: Train Separate Models for Clinician and AI Alignment ---\n",
    "\n",
    "# Define target variables representing alignment with Clinician and AI\n",
    "# For Clinician: 1 = Alignment with Clinician (no discrepancy), 0 = Discrepancy\n",
    "# For AI: 1 = Alignment with AI (discrepancy), 0 = No discrepancy\n",
    "# Ensure this aligns with your data's semantics\n",
    "\n",
    "# Train model for Clinician alignment\n",
    "print(\"\\n--- Training Random Forest for Clinician Alignment ---\")\n",
    "clinician_importance, rf_clinician, scaler_clinician, X_test_clinician, y_test_clinician = compute_feature_importance_rf(\n",
    "    X_imputed, (y_discrepancy == 0).astype(int), X.columns, n_estimators=200, random_state=42\n",
    ")\n",
    "\n",
    "# Train model for AI alignment\n",
    "print(\"\\n--- Training Random Forest for AI Alignment ---\")\n",
    "ai_importance, rf_ai, scaler_ai, X_test_ai, y_test_ai = compute_feature_importance_rf(\n",
    "    X_imputed, (y_discrepancy == 1).astype(int), X.columns, n_estimators=200, random_state=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190bf3c8-42ce-4aa5-b4c6-1f622f9aa467",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name_mapping = {\n",
    "    'output_step': '12-hour total output, mL',\n",
    "    'SOFA': 'SOFA score',\n",
    "    'cumulated_balance': 'Cumulative balance, mL',\n",
    "    'Creatinine': 'Creatinine, mg/dL',\n",
    "    'Platelets_count': 'Platelet count, ×10^3/µL',\n",
    "    'Chloride': 'Chloride, mEq/L',\n",
    "    'BUN': 'BUN, mg/dL',\n",
    "    'Anion_Gap': 'Anion gap, mEq/L',\n",
    "    'Calcium': 'Calcium, mg/dL',\n",
    "    'input_total': 'Total input, mL',\n",
    "    'WBC_count': 'WBC count, ×10^3/µL',\n",
    "    'Total_bili': 'Total bilirubin, mg/dL',\n",
    "    'Phosphorous': 'Phosphorus, mg/dL',\n",
    "    'O2flow': 'O2 flow, L/min',\n",
    "    'output_total': 'Total output, mL',\n",
    "    'Weight_kg': 'Weight, kg',\n",
    "    'RASS': 'RASS score',\n",
    "    'Sodium': 'Sodium, mEq/L',\n",
    "    'Temp_C': 'Temperature, °C',\n",
    "    'age': 'Age, years',\n",
    "    'max_dose_vaso': 'Maximum vasopressor dose, µg/kg/min',\n",
    "    'PAWmean': 'Mean airway pressure, cmH2O',\n",
    "    'GCS': 'GCS score',\n",
    "    'SGOT': 'AST (SGOT), U/L',\n",
    "    'PT': 'PT, s',\n",
    "    'PTT': 'PTT, s',\n",
    "    'RBC_count': 'RBC count, ×10^6/µL',\n",
    "    'LDH': 'LDH, U/L',\n",
    "    'Ht': 'Hematocrit, %',\n",
    "    'RR': 'Respiratory rate, breaths/min',\n",
    "    'HCO3': 'Bicarbonate, mEq/L',\n",
    "    'SpO2': 'SpO2, %',\n",
    "    'Ionised_Ca': 'Ionized calcium, mmol/L',\n",
    "    'Hb': 'Hemoglobin, g/dL',\n",
    "    'FiO2_1': 'FiO2, %',\n",
    "    'SGPT': 'ALT (SGPT), U/L',\n",
    "    'Shock_Index': 'Shock index',\n",
    "    'Glucose': 'Glucose, mg/dL',\n",
    "    'HR': 'Heart rate, beats/min',\n",
    "    'MinuteVentil': 'Minute ventilation, L/min',\n",
    "    'MeanBP': 'Mean blood pressure, mmHg',\n",
    "    'INR': 'INR',\n",
    "    'Potassium': 'Potassium, mEq/L',\n",
    "    'Fibrinogen': 'Fibrinogen, mg/dL',\n",
    "    'Arterial_pH': 'Arterial pH',\n",
    "    'PaO2_FiO2': 'PaO2/FiO2 ratio',\n",
    "    'TidalVolume': 'Tidal volume, mL',\n",
    "    'paO2': 'PaO2, mmHg',\n",
    "    'Albumin': 'Albumin, g/dL',\n",
    "    'DiaBP': 'Diastolic blood pressure, mmHg',\n",
    "    'input_step': '12-hour total input, mL',\n",
    "    'Magnesium': 'Magnesium, mg/dL',\n",
    "    'SysBP': 'Systolic blood pressure, mmHg',\n",
    "    'PAWpeak': 'Peak airway pressure, cmH2O',\n",
    "    'extubated': 'Extubated (yes/no)',\n",
    "    'Arterial_BE': 'Arterial base excess, mEq/L',\n",
    "    'PAWplateau': 'Plateau airway pressure, cmH2O',\n",
    "    'Height_cm': 'Height, cm',\n",
    "    'CVP': 'cCntral venous pressure, mmHg',\n",
    "    'paCO2': 'PaCO2, mmHg',\n",
    "    'Arterial_lactate': 'Arterial lactate, mmol/L',\n",
    "    'PEEP': 'PEEP, cmH2O',\n",
    "    'CK_MB': 'CK-MB, ng/mL',\n",
    "    'ETCO2': 'End-tidal CO2, mmHg',\n",
    "    'Troponin': 'Troponin, ng/mL',\n",
    "    'mechvent': 'Mechanical ventilation (yes/no)',\n",
    "    'Absolute_Neutrophil_Count': 'Absolute neutrophil count, ×10^3/µL',\n",
    "    'SIRS': 'SIRS criteria',\n",
    "    'SaO2': 'SaO2, %',\n",
    "    'Triglyceride': 'Triglycerides, mg/dL',\n",
    "    'SvO2': 'SvO2, %',\n",
    "    'PAPsys': 'Pulmonary artery systolic pressure, mmHg',\n",
    "    'PAPdia': 'Pulmonary artery diastolic pressure, mmHg',\n",
    "    're_admission': 're-admission (yes/no)',\n",
    "    'PAPmean': 'Mean pulmonary artery pressure, mmHg',\n",
    "    'Creatinine_Urine': 'Urine creatinine, mg/dL',\n",
    "    'gender': 'gender (M/F)',\n",
    "    'BNP': 'BNP, pg/mL',\n",
    "    'CRP': 'CRP, mg/L',\n",
    "    'Urea_Nitrogen_Urine': 'Urine urea nitrogen, mg/dL',\n",
    "    'Sodium_Urine': 'Urine sodium, mEq/L',\n",
    "    'Potassium_Urine': 'Urine potassium, mEq/L',\n",
    "    'Iron': 'Iron, µg/dL',\n",
    "    'Ammonia': 'Ammonia, µg/dL',\n",
    "    'Thyroid_Stimulating_Hormone': 'TSH, mIU/L',\n",
    "    'Total_protein': 'Total protein, g/dL',\n",
    "    'CI': 'Cardiac index, L/min/m²',\n",
    "    'ACT': 'ACT, s',\n",
    "    'T3': 'T3, ng/dL',\n",
    "    'Gamma_Glutamyltransferase': 'GGT, U/L',\n",
    "    'Heparin_LMW': 'Low molecular weight heparin (yes/no)',\n",
    "    'APACHEII_Renal_Failure': 'APACHE II renal failure score',\n",
    "    'Osmolality_Urine': 'Urine osmolality, mOsm/kg'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c9b216-578e-49bd-8a79-f921041e310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# Rename importance columns for clarity\n",
    "clinician_importance.rename(columns={'importance': 'importance_clinician'}, inplace=True)\n",
    "ai_importance.rename(columns={'importance': 'importance_ai'}, inplace=True)\n",
    "\n",
    "# Merge clinician and AI importances on the 'feature' column\n",
    "importance_df = clinician_importance.merge(ai_importance, on='feature')\n",
    "\n",
    "# Calculate the average importance of each feature\n",
    "importance_df['average_importance'] = (\n",
    "    importance_df['importance_clinician'] + importance_df['importance_ai']\n",
    ") / 2\n",
    "\n",
    "# Calculate the disparity (absolute difference) between AI and clinician importances\n",
    "importance_df['disparity'] = (\n",
    "    importance_df['importance_ai'] - importance_df['importance_clinician']\n",
    ").abs()\n",
    "\n",
    "# Sort features by average importance in descending order\n",
    "importance_df_sorted = importance_df.sort_values(by='average_importance', ascending=False)\n",
    "\n",
    "# Select top 10 features based on average importance\n",
    "top_n_average = 10\n",
    "top_average_features = importance_df_sorted.head(top_n_average)['feature'].tolist()\n",
    "\n",
    "# Select top 5 features with the highest disparity, excluding the top average features\n",
    "top_disparity_features = (\n",
    "    importance_df_sorted[~importance_df_sorted['feature'].isin(top_average_features)]\n",
    "    .sort_values(by='disparity', ascending=False)\n",
    "    .head(5)['feature']\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "# Combine the selected features for plotting\n",
    "features_to_plot = top_average_features + top_disparity_features\n",
    "\n",
    "# Prepare the DataFrame for plotting by selecting only the relevant features\n",
    "plot_data = importance_df[importance_df['feature'].isin(features_to_plot)].copy()\n",
    "\n",
    "# Map original feature names to display names using feature_name_mapping\n",
    "plot_data['feature_display'] = plot_data['feature'].map(feature_name_mapping)\n",
    "\n",
    "# Handle any features that might not have a mapping\n",
    "missing_mappings = plot_data['feature_display'].isnull()\n",
    "if missing_mappings.any():\n",
    "    print(\"Warning: The following features are missing mappings and will use original names:\")\n",
    "    print(plot_data.loc[missing_mappings, 'feature'])\n",
    "    plot_data['feature_display'].fillna(plot_data['feature'], inplace=True)\n",
    "\n",
    "# Determine the order of features: top 10 by average importance, then top 5 by disparity\n",
    "plot_data['feature_display'] = pd.Categorical(\n",
    "    plot_data['feature_display'],\n",
    "    categories=[feature_name_mapping.get(f, f) for f in features_to_plot],\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Melt the DataFrame to long format for seaborn\n",
    "plot_melted = plot_data.melt(\n",
    "    id_vars=['feature_display'],\n",
    "    value_vars=['importance_clinician', 'importance_ai'],\n",
    "    var_name='Source',\n",
    "    value_name='Importance'\n",
    ")\n",
    "\n",
    "# Compute AUROC Scores for Clinician and AI Models\n",
    "# Predict probabilities for Clinician Alignment Model\n",
    "y_proba_clinician = rf_clinician.predict_proba(X_test_clinician)[:, 1]\n",
    "auc_clinician = roc_auc_score(y_test_clinician, y_proba_clinician)\n",
    "\n",
    "# Predict probabilities for AI Alignment Model\n",
    "y_proba_ai = rf_ai.predict_proba(X_test_ai)[:, 1]\n",
    "auc_ai = roc_auc_score(y_test_ai, y_proba_ai)\n",
    "\n",
    "# Replace source names with more readable labels and include AUROC scores\n",
    "plot_melted['Source'] = plot_melted['Source'].map({\n",
    "    'importance_clinician': f'Clinician-initiated RRT only (AUROC={auc_clinician:.2f})',\n",
    "    'importance_ai': f'AI-recommended RRT only (AUROC={auc_ai:.2f})'\n",
    "})\n",
    "\n",
    "# Define color palette with updated labels\n",
    "palette = {\n",
    "    f'Clinician-initiated RRT only (AUROC={auc_clinician:.2f})': '#d0d9f0',\n",
    "    f'AI-recommended RRT only (AUROC={auc_ai:.2f})': '#6b8ac5'\n",
    "}\n",
    "\n",
    "# Set plot style for publication quality\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "# Create the plot with adjusted figure size for better readability\n",
    "plt.figure(figsize=(14, 12))  # Width x Height in inches\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "# Create a horizontal bar plot\n",
    "ax = sns.barplot(\n",
    "    data=plot_melted,\n",
    "    x='Importance',\n",
    "    y='feature_display',  # Use the display names for the y-axis\n",
    "    hue='Source',\n",
    "    palette=palette,\n",
    "    errorbar=None,  # Remove confidence intervals\n",
    "    edgecolor='black',\n",
    "    linewidth=1.5\n",
    ")\n",
    "\n",
    "# Customize the plot labels\n",
    "plt.xlabel('Feature importance', fontsize=16, labelpad=10)\n",
    "plt.ylabel('Feature', fontsize=16, labelpad=10)\n",
    "\n",
    "# Annotate bars with importance values, skipping very small values to avoid \"0.000\"\n",
    "threshold = 0.001  # Define a threshold below which annotations are skipped\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    if width >= threshold:\n",
    "        y = p.get_y() + p.get_height() / 2\n",
    "        ax.text(width + 0.001, y, f\"{width:.4f}\", va='center', fontsize=12)\n",
    "    # If width < threshold, skip annotation to avoid clutter\n",
    "\n",
    "# Add a horizontal dotted line to separate the top 10 and the top 5\n",
    "plt.axhline(y=top_n_average - 0.5, color='grey', linestyle='--', linewidth=1)\n",
    "\n",
    "# Adjust legend to be outside the plot, in the upper left without a title\n",
    "plt.legend(\n",
    "    title=None,  # Remove the legend title\n",
    "    fontsize=14,\n",
    "    title_fontsize=16,\n",
    "    loc='upper left',\n",
    "    bbox_to_anchor=(1.00, 1)  # Move the legend slightly to the right\n",
    ")\n",
    "\n",
    "# Set x-axis limits for better visualization\n",
    "plt.xlim([0, 0.16])\n",
    "\n",
    "# Enhance spacing between y-axis labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure in high resolution\n",
    "plt.savefig(os.path.join(fig_path, 'mimic_feature_importance.png'), dpi=300, bbox_inches='tight')\n",
    "plt.savefig(os.path.join(fig_path, 'mimic_feature_importance.eps'), dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71f50f7-e40b-4983-8835-0dda5f840f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "C_ICUSTAYID = 'icustayid' \n",
    "data_dir = '/home/lkapral/RRT_mimic_iv/data/model'\n",
    "\n",
    "penalties = []\n",
    "treated_fractions = []\n",
    "\n",
    "# We will store raw WIS metrics first, then scale later\n",
    "\n",
    "val_wis_01_raw = []\n",
    "val_wis_05_raw = []\n",
    "val_wis_means_raw = []\n",
    "val_wis_95_raw = []\n",
    "val_ql_95_raw = []\n",
    "wis_indices = []\n",
    "\n",
    "train_wis_01_raw = []\n",
    "train_wis_05_raw = []\n",
    "train_wis_means_raw = []\n",
    "train_wis_95_raw = []\n",
    "\n",
    "penalties = []\n",
    "treated_fractions = []\n",
    "\n",
    "val_wis_01_raw = []\n",
    "val_wis_05_raw = []\n",
    "val_wis_means_raw = []\n",
    "val_wis_95_raw = []\n",
    "val_ql_95_raw = []\n",
    "wis_indices = []\n",
    "\n",
    "train_wis_01_raw = []\n",
    "train_wis_05_raw = []\n",
    "train_wis_means_raw = []\n",
    "train_wis_95_raw = []\n",
    "\n",
    "for i in range(-0, 35, 1):\n",
    "    penal_amount = i / 100.\n",
    "    out_dir = os.path.join(data_dir, \"models_penal\", str(penal_amount))\n",
    "    model_para_dir = os.path.join(out_dir, \"model_params_40\")    \n",
    "    best_model_dir =  os.path.join(model_para_dir, \"best\") \n",
    "    model_stats_path = os.path.join(out_dir, \"model_stats.csv\")\n",
    "    additional_vars_path = os.path.join(best_model_dir, \"additional_vars_best.pkl\")\n",
    "\n",
    "    if not os.path.exists(model_stats_path) or not os.path.exists(additional_vars_path):\n",
    "        print(f\"Skipping penalty {penal_amount}, required files not found.\")\n",
    "        continue\n",
    "\n",
    "    # Load model stats and select top 5 models based on val_bootwis_0.05\n",
    "    all_model_stats = pd.read_csv(model_stats_path)\n",
    "    wis_index = all_model_stats['val_bootwis_0.05'].idxmax()\n",
    "    top_5_models = all_model_stats.nlargest(25, 'val_bootwis_0.05')\n",
    "\n",
    "    # Average validation metrics\n",
    "    val_wis_05_avg = top_5_models['val_bootwis_0.05'].mean()\n",
    "    val_wis_01_avg = top_5_models['val_bootwis_0.01'].mean()\n",
    "    val_wis_mean_avg = top_5_models['val_bootwis_mean'].mean()\n",
    "    val_wis_95_avg = top_5_models['val_bootwis_0.95'].mean()\n",
    "\n",
    "    # Average training metrics\n",
    "    train_wis_05_avg = top_5_models['train_bootwis_0.05'].mean()\n",
    "    train_wis_mean_avg = top_5_models['train_bootwis_mean'].mean()\n",
    "    train_wis_95_avg = top_5_models['train_bootwis_0.95'].mean()\n",
    "\n",
    "    # Average QL metric\n",
    "    ql_95_avg = top_5_models['train_bootql_0.95'].mean()\n",
    "\n",
    "    # Append averaged metrics\n",
    "    val_wis_means_raw.append(val_wis_mean_avg)\n",
    "    val_wis_01_raw.append(val_wis_01_avg)\n",
    "    val_wis_05_raw.append(val_wis_05_avg)\n",
    "    val_wis_95_raw.append(val_wis_95_avg)\n",
    "    val_ql_95_raw.append(ql_95_avg)\n",
    "\n",
    "    train_wis_means_raw.append(train_wis_mean_avg)\n",
    "    train_wis_05_raw.append(train_wis_05_avg)\n",
    "    train_wis_95_raw.append(train_wis_95_avg)\n",
    "\n",
    "    # Load additional variables and compute treated fraction for each top model\n",
    "    treated_fractions_per_model = []\n",
    "    \n",
    "    # Directory where top5 models are saved\n",
    "    top5_dir = os.path.join(model_para_dir, 'top5')\n",
    "    \n",
    "    # Load each of the top 5 models' additional variables\n",
    "    for idx in range(5):  # For each of the top 5 models\n",
    "        top_vars_path = os.path.join(top5_dir, f'additional_vars_top5_{idx}.pkl')\n",
    "        \n",
    "        if not os.path.exists(top_vars_path):\n",
    "            print(f\"Missing top5 vars file for model {idx} at penalty {penal_amount}\")\n",
    "            continue\n",
    "    \n",
    "        with open(top_vars_path, 'rb') as f:\n",
    "            top_vars = pickle.load(f)\n",
    "    \n",
    "        # Get probabilities for this top model\n",
    "        prob_treatment = top_vars['model_probs']  # Shape (n_samples,)\n",
    "        # Calculate treated fraction\n",
    "        df_val_temp = top_vars['metadata_val'].copy()\n",
    "        df_val_temp['prob_treatment'] = prob_treatment[:, 1]\n",
    "        max_prob_per_patient = df_val_temp.groupby(C_ICUSTAYID)['prob_treatment'].max()\n",
    "        n_treated = (max_prob_per_patient > 0.5).sum()\n",
    "        treated_fraction = (n_treated / max_prob_per_patient.shape[0]) * 100  # Use same count as original\n",
    "        \n",
    "        treated_fractions_per_model.append(treated_fraction)\n",
    "    \n",
    "    # Average across top 5 models\n",
    "    if len(treated_fractions_per_model) > 0:\n",
    "        treated_fraction_avg = np.mean(treated_fractions_per_model)\n",
    "    else:\n",
    "        treated_fraction_avg = 0  # Handle missing files case\n",
    "    \n",
    "    treated_fractions.append(treated_fraction_avg)\n",
    "    penalties.append(penal_amount * 100)\n",
    "    \n",
    "    wis_indices.append(wis_index)\n",
    "\n",
    "# Find the global maximum of WIS_95 across all penalties for scaling\n",
    "all_wis_95 = np.array(val_wis_95_raw)  # combine training and val if needed\n",
    "#max_wis_95_over_all = np.nanmax(all_wis_95)\n",
    "max_wis_95_over_all = 100\n",
    "\n",
    "\n",
    "# Scale all WIS metrics by max_wis_95_over_all\n",
    "val_wis_means = np.array(val_wis_means_raw) / max_wis_95_over_all * 100\n",
    "val_wis_01 = np.array(val_wis_01_raw) / max_wis_95_over_all * 100\n",
    "val_wis_05 = np.array(val_wis_05_raw) / max_wis_95_over_all * 100\n",
    "val_wis_95 = np.array(val_wis_95_raw) / max_wis_95_over_all * 100\n",
    "val_ql_95 = np.array(val_ql_95_raw) / max_wis_95_over_all * 100\n",
    "\n",
    "train_wis_means = np.array(train_wis_means_raw) / max_wis_95_over_all * 100\n",
    "train_wis_05 = np.array(train_wis_05_raw) / max_wis_95_over_all * 100\n",
    "train_wis_95 = np.array(train_wis_95_raw) / max_wis_95_over_all * 100\n",
    "\n",
    "avg_wis_means = (val_wis_means + train_wis_means) / 2.\n",
    "avg_wis_05 = (val_wis_05 + train_wis_05) / 2.\n",
    "avg_wis_95 = (val_wis_95 + train_wis_95) / 2.\n",
    "\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "sns.set(style=\"ticks\")\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "color1 = '#6b8ac5'\n",
    "ax1.set_xlabel('RRT initiation penalty (% of mortality penalty)')\n",
    "ax1.set_ylabel('Performance (% of maximum reward)', color=color1)\n",
    "ax1.plot(penalties, val_wis_means, marker='o', color=color1, label='AI performance on validation set', linewidth=2)\n",
    "ax1.fill_between(penalties, val_wis_05, val_wis_95, color=color1, alpha=0.5)\n",
    "ax1.tick_params(axis='y', labelcolor=color1)\n",
    "\n",
    "x_pos_text = -0.1  # slightly to the left of the first penalty\n",
    "\n",
    "# Add a line for clinician performance (QL 95%) - also scaled by max WIS_95\n",
    "clinician_mean = np.mean(val_ql_95)\n",
    "clinician_std = np.std(val_ql_95)\n",
    "ax1.plot(penalties, [clinician_mean for _ in val_ql_95], color='#d0d9f0', linestyle='--', linewidth=2)\n",
    "ax1.fill_between(penalties, clinician_mean + clinician_std, clinician_mean - clinician_std, color='#d0d9f0', alpha=0.5)\n",
    "ax1.text(x_pos_text+1, clinician_mean + clinician_std + 0.1, \"Clinicians' performance\", color=color1, va='bottom')\n",
    "\n",
    "# Secondary axis for treated patients\n",
    "ax2 = ax1.twinx()\n",
    "color2 = 'black'\n",
    "ax2.set_ylabel('Proportion of patients receiving RRT (%)', color=color2)\n",
    "ax2.plot(penalties, treated_fractions, marker='s', color=color2, label='AI-recommended RRT rate', linewidth=2)\n",
    "ax2.tick_params(axis='y', labelcolor=color2)\n",
    "\n",
    "# Add dotted reference lines and text (on treated patients axis)\n",
    "mimic_line = 3.5   \n",
    "muw_line = 10.5     \n",
    "ax2.axhline(y=mimic_line, color='black', linestyle=':', linewidth=2)\n",
    "ax2.axhline(y=muw_line, color='black', linestyle=':', linewidth=2)\n",
    "ax1.set_ylim([40, 85])\n",
    "ax2.set_ylim([0, 30])\n",
    "\n",
    "# Add text above these lines. \n",
    "# Positioning: at a fixed x-position, adjust y-position slightly\n",
    "ax2.text( 22.5, mimic_line+ 0.2, \"MIMIC (3.6% clinician-initiated RRT)\", color='black', va='bottom')\n",
    "ax2.text( 22.5 , muw_line+ 0.3, \"MUW (10.5% clinician-initiated RRT)\", color='black', va='bottom')\n",
    "\n",
    "# ============================\n",
    "# New Code: Add vertical dotted line for selected model\n",
    "# ============================\n",
    "\n",
    "selected_penalty = 22  # 11% penalty\n",
    "\n",
    "if selected_penalty in penalties:\n",
    "    \n",
    "    ax1.axvline(x=selected_penalty, color='salmon', linestyle=':', linewidth=2)  # Dotted line, no label\n",
    "    \n",
    "    # Add text label near the vertical line\n",
    "    # Position the text slightly above the top of the plot\n",
    "    ax1.text(selected_penalty - 0.8, ax1.get_ylim()[1] - 18, 'Selected model', color='salmon', rotation=90, \n",
    "             verticalalignment='top', horizontalalignment='left')\n",
    "else:\n",
    "    print(f\"Selected penalty {selected_penalty}% not found in penalties list.\")\n",
    "\n",
    "# ============================\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.grid(False)\n",
    "\n",
    "plt.xlim([-0.5, 34.5])\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left', bbox_to_anchor=(1.05, 1))  # Move the legend slightly to the right)\n",
    "ax1.yaxis.grid(False)\n",
    "ax1.xaxis.grid(False)\n",
    "\n",
    "# Ensure you have 'fig_path' defined elsewhere in your script\n",
    "# Do NOT redefine or overwrite 'fig_path' here\n",
    "# Example:\n",
    "# fig_path = '/home/lkapral/RRT_mimic_iv/figures'\n",
    "\n",
    "fig.savefig(os.path.join(fig_path, 'mimic_penalties.png'), dpi=300, bbox_inches='tight')\n",
    "fig.savefig(os.path.join(fig_path, 'mimic_penalties.eps'),  format='eps', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0461bcd7-b45a-48b0-b825-e8efbf2235da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834a336b-0cf1-4b40-99d9-799a1404d466",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pen_data = pd.DataFrame(np.array(penalties)/100., columns=['penalties'] )\n",
    "pen_data['wis_indices'] = np.array(wis_indices)\n",
    "pen_data['treated_fractions'] = np.array(treated_fractions)\n",
    "pen_data['val_wis_01'] = np.array(val_wis_01)\n",
    "pen_data['val_wis_05'] = np.array(val_wis_05)\n",
    "pen_data['val_wis_mean'] = np.array(val_wis_means)\n",
    "pen_data['val_wis_95'] = np.array(val_wis_95)\n",
    "\n",
    "\n",
    "pen_data['train_wis_05'] = np.array(train_wis_05)\n",
    "pen_data['avg_wis_05'] = np.array(avg_wis_05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df232029-cc7b-4d67-a31e-34acf0b9eba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pen_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c254450f-3340-4412-b3da-2a50627de997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e4e206-cf2b-4d03-9375-93bfb92d6f0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f87259d-287b-42fa-a001-630ab23d2733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefcb690-cdb2-4e6e-a202-42eb30c536cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba81316-d25f-4f31-afbd-5d92ca3b06b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f1dd9f-ef86-4512-83cb-7f7d57d30b2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7633d4c-bdb1-4cc5-b43c-75b70552e656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44648bfa-aefd-4250-b4da-79a3e0d082fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080545ba-5f93-4879-88ae-b1fe8276d633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60826d3-313d-412b-ba3f-f45f52e5e1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186afff1-e056-4c87-a9c0-da32343ea8f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf0b154-5f7c-4b65-8b31-2e47e5fc6375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dc0cb9-e0d1-43f0-9e79-6b8356b4732d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443e6f98-8add-4646-bd78-f9a3d05dde6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d74353-9ac4-41d1-831a-c8d15cc194a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158a78a8-bdea-465c-b418-41c857f03bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b911315-9054-4c6a-a918-0a9a3cd98373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166de1f9-0819-4d26-bda0-42c401882c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
